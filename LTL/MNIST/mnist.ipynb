{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "image_size = 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "class DANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "                    nn.Conv2d(1, 64, kernel_size=5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(64, 50, kernel_size=5),\n",
    "                    nn.BatchNorm2d(50),\n",
    "                    nn.Dropout2d(),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "                \n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(50 * 4 * 4, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 10),\n",
    "                )\n",
    "\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "                    nn.Linear(50 * 4 * 4, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 2),\n",
    "                )\n",
    "    def forward(self, input_data, alpha):\n",
    "        input_data = input_data.expand(input_data.data.shape[0], 1, 28, 28)\n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, 50 * 4 * 4)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return class_output, domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DANN(train_loader, model, criterion, optimizer, epoches):\n",
    "    model.train()\n",
    "    data_target_iter = iter(train_loader)\n",
    "    src_domain_label = torch.ones(batch_size).long()\n",
    "    tgt_domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    for e in range(epoches):\n",
    "        data_target_iter = iter(train_loader)\n",
    "        correct_source_domain, correct_tgt_domain = 0, 0\n",
    "        total = 0\n",
    "        for i in range(20):\n",
    "            # Src\n",
    "            source, source_label = data_target_iter.next()\n",
    "            total += source.size(0)\n",
    "\n",
    "            source, source_label = source.to(device), source_label.to(device)\n",
    "\n",
    "            class_output, domain_output = model(source, alpha)\n",
    "\n",
    "            loss_s_label = criterion(class_output, source_label)\n",
    "            loss_s_domain = criterion(domain_output, src_domain_label)\n",
    "\n",
    "            _, predicted = torch.max(domain_output.data, 1)\n",
    "            correct_source_domain += predicted.eq(src_domain_label.data).cpu().sum().item()\n",
    "\n",
    "            # Tgt\n",
    "            target, target_label  = data_target_iter.next()\n",
    "            target, target_label = target.to(device), target_label.to(device)\n",
    "\n",
    "            class_output, domain_output = model(target, alpha)\n",
    "            \n",
    "            loss_t_label = criterion(class_output, target_label)\n",
    "            loss_t_domain = criterion(domain_output, tgt_domain_label)\n",
    "\n",
    "            _, predicted = torch.max(domain_output.data, 1)\n",
    "            correct_tgt_domain += predicted.eq(tgt_domain_label.data).cpu().sum().item()\n",
    "\n",
    "            loss = loss_s_label + loss_s_domain + loss_t_domain + loss_t_label\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"{e}: source correct: {correct_source_domain/total}, target correct: {correct_tgt_domain/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "dann = DANN()\n",
    "dann.to(device)\n",
    "optimizer = optim.Adam(dann.parameters(), lr=0.001) \n",
    "\n",
    "train_DANN(train_loader, dann, criterion, optimizer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear (50 * 4 * 4, 1000), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear (1000, 100), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear (100, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(256, 32 * 32 * 3)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader = Linear()\n",
    "leader.train()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(leader.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        feature = dann.feature(images)\n",
    "        \n",
    "    outputs = leader(feature)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/30], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(leader.state_dict(), 'model_batch_A.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(data_iter)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.no_grad():\n",
    "        feature = dann.feature(images)\n",
    "    outputs = leader(feature)\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(f\"B all on A, Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
