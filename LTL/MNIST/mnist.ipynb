{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hoq27tYVdEq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VuwcCuomdEq8"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "batch_size = 256\n",
        "image_size = 28*28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZugygmOUdEq9"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=256, shuffle=False, drop_last = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "JBE9Pm42j13V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Linear, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear (28 * 28 * 1, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (1000, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (100, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28 * 1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "YoCUCWQCjsul"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_classification(testloader, model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for a, b in testloader:\n",
        "            a, b = a.to(device), b.to(device)\n",
        "            outputs = model(a)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += b.size(0)\n",
        "            correct += (predicted == b).sum().item()\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "dobfuqghTGre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = Linear().to(device)\n",
        "base.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(base.parameters(), lr=0.005)\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "for epoch in range(15):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = base(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    with torch.no_grad():\n",
        "        torch.save(base.state_dict(), f'Basemodel_batch_A_{epoch}.pth')\n",
        "\n",
        "    batch_acc = test_classification(testloader, base)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/15], Loss: {loss.item():.4f}, test_acc: {batch_acc}\")\n",
        "\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "for e in range(15):\n",
        "    with torch.no_grad():\n",
        "        load_model = Linear()\n",
        "        load_model.load_state_dict(torch.load(f'Basemodel_batch_A_{e}.pth'))\n",
        "        load_model = load_model.to(device)\n",
        "        outputs = load_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        batch_acc = test_classification(testloader, load_model)\n",
        "\n",
        "        print(f\"Epoch [{e+1}/15], Loss: {loss.item():.4f}, test_acc: {batch_acc}\")"
      ],
      "metadata": {
        "id": "WEnbz6Tkj48u",
        "outputId": "ece3fd62-db50-4e2b-92ab-f23be646e0d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 2.3055, test_acc: 0.2936698717948718\n",
            "Epoch [2/30], Loss: 2.6849, test_acc: 0.09805689102564102\n",
            "Epoch [3/30], Loss: 4.7147, test_acc: 0.10116185897435898\n",
            "Epoch [4/30], Loss: 2.8637, test_acc: 0.21764823717948717\n",
            "Epoch [5/30], Loss: 2.7097, test_acc: 0.16075721153846154\n",
            "Epoch [6/30], Loss: 2.8161, test_acc: 0.37159455128205127\n",
            "Epoch [7/30], Loss: 2.5747, test_acc: 0.21424278846153846\n",
            "Epoch [8/30], Loss: 2.3344, test_acc: 0.2364783653846154\n",
            "Epoch [9/30], Loss: 2.0577, test_acc: 0.296474358974359\n",
            "Epoch [10/30], Loss: 1.8395, test_acc: 0.35466746794871795\n",
            "Epoch [11/30], Loss: 1.7064, test_acc: 0.5071113782051282\n",
            "Epoch [12/30], Loss: 1.6011, test_acc: 0.5448717948717948\n",
            "Epoch [13/30], Loss: 1.4855, test_acc: 0.5503806089743589\n",
            "Epoch [14/30], Loss: 1.3465, test_acc: 0.547676282051282\n",
            "Epoch [15/30], Loss: 1.2077, test_acc: 0.5735176282051282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Uss77ufrdEq9"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DANN, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "                    nn.Conv2d(1, 64, kernel_size=5),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Conv2d(64, 50, kernel_size=5),\n",
        "                    nn.BatchNorm2d(50),\n",
        "                    nn.Dropout2d(),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.ReLU(True)\n",
        "                )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                    nn.Linear(50 * 4 * 4, 100),\n",
        "                    nn.BatchNorm1d(100),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Dropout(),\n",
        "                    nn.Linear(100, 100),\n",
        "                    nn.BatchNorm1d(100),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(100, 10),\n",
        "                )\n",
        "\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "                    nn.Linear(50 * 4 * 4, 100),\n",
        "                    nn.BatchNorm1d(100),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(100, 2),\n",
        "                )\n",
        "    def forward(self, input_data, alpha):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 1, 28, 28)\n",
        "        feature = self.feature(input_data)\n",
        "        feature = feature.view(-1, 50 * 4 * 4)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.classifier(feature)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return class_output, domain_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xpTXV-5tdEq9"
      },
      "outputs": [],
      "source": [
        "def train_DANN(train_loader, model, criterion, optimizer, epoches):\n",
        "    model.train()\n",
        "    src_domain_label = torch.ones(batch_size).long().to(device)\n",
        "    tgt_domain_label = torch.zeros(batch_size).long().to(device)\n",
        "\n",
        "    alpha = 0.005\n",
        "\n",
        "    for e in range(epoches):\n",
        "        data_target_iter = iter(train_loader)\n",
        "        correct_source_domain, correct_tgt_domain = 0, 0\n",
        "        total = 0\n",
        "        for i in range(40):\n",
        "            # Src\n",
        "            source, source_label = next(data_target_iter)\n",
        "            total += source.size(0)\n",
        "\n",
        "            source, source_label = source.to(device), source_label.to(device)\n",
        "\n",
        "            class_output, domain_output = model(source, alpha)\n",
        "\n",
        "            loss_s_label = criterion(class_output, source_label)\n",
        "            loss_s_domain = criterion(domain_output, src_domain_label)\n",
        "\n",
        "            _, predicted = torch.max(domain_output.data, 1)\n",
        "            correct_source_domain += predicted.eq(src_domain_label.data).cpu().sum().item()\n",
        "\n",
        "            # Tgt\n",
        "            target, target_label  = next(data_target_iter)\n",
        "            target, target_label = target.to(device), target_label.to(device)\n",
        "\n",
        "            class_output, domain_output = model(target, alpha)\n",
        "\n",
        "            loss_t_label = criterion(class_output, target_label)\n",
        "            loss_t_domain = criterion(domain_output, tgt_domain_label)\n",
        "\n",
        "            _, predicted = torch.max(domain_output.data, 1)\n",
        "            correct_tgt_domain += predicted.eq(tgt_domain_label.data).cpu().sum().item()\n",
        "\n",
        "            loss = loss_s_label + loss_s_domain + loss_t_domain + loss_t_label\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if ((e + 1) % 5 == 0):\n",
        "            print(f\"{e}: source correct: {correct_source_domain/total}, target correct: {correct_tgt_domain/total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "boZajnHxdEq9",
        "outputId": "36f5a9e1-284a-47ef-acb0-c225174710fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: source correct: 0.41337890625, target correct: 0.5865234375\n",
            "1: source correct: 0.80703125, target correct: 0.19306640625\n",
            "2: source correct: 0.1201171875, target correct: 0.8833984375\n",
            "3: source correct: 0.58515625, target correct: 0.415234375\n",
            "4: source correct: 0.8009765625, target correct: 0.19931640625\n",
            "5: source correct: 0.29814453125, target correct: 0.70107421875\n",
            "6: source correct: 0.0919921875, target correct: 0.91083984375\n",
            "7: source correct: 0.6775390625, target correct: 0.325390625\n",
            "8: source correct: 0.84013671875, target correct: 0.1609375\n",
            "9: source correct: 0.9439453125, target correct: 0.05595703125\n",
            "10: source correct: 0.989453125, target correct: 0.01162109375\n",
            "11: source correct: 0.77373046875, target correct: 0.2275390625\n",
            "12: source correct: 0.0857421875, target correct: 0.91240234375\n",
            "13: source correct: 0.01416015625, target correct: 0.98662109375\n",
            "14: source correct: 0.00078125, target correct: 0.99912109375\n",
            "15: source correct: 0.0, target correct: 1.0\n",
            "16: source correct: 0.0, target correct: 1.0\n",
            "17: source correct: 0.0, target correct: 1.0\n",
            "18: source correct: 0.0, target correct: 1.0\n",
            "19: source correct: 0.025, target correct: 0.975\n",
            "20: source correct: 1.0, target correct: 0.0\n",
            "21: source correct: 0.9998046875, target correct: 9.765625e-05\n",
            "22: source correct: 0.99970703125, target correct: 9.765625e-05\n",
            "23: source correct: 0.99921875, target correct: 0.00029296875\n",
            "24: source correct: 0.99921875, target correct: 0.00087890625\n",
            "25: source correct: 0.996484375, target correct: 0.00322265625\n",
            "26: source correct: 0.99287109375, target correct: 0.00654296875\n",
            "27: source correct: 0.98837890625, target correct: 0.01142578125\n",
            "28: source correct: 0.813671875, target correct: 0.18291015625\n",
            "29: source correct: 0.05556640625, target correct: 0.94833984375\n",
            "30: source correct: 0.0458984375, target correct: 0.95419921875\n",
            "31: source correct: 0.0453125, target correct: 0.95390625\n",
            "32: source correct: 0.04423828125, target correct: 0.95517578125\n",
            "33: source correct: 0.04384765625, target correct: 0.9609375\n",
            "34: source correct: 0.04443359375, target correct: 0.95810546875\n",
            "35: source correct: 0.049609375, target correct: 0.94873046875\n",
            "36: source correct: 0.071484375, target correct: 0.9345703125\n",
            "37: source correct: 0.11298828125, target correct: 0.88740234375\n",
            "38: source correct: 0.39677734375, target correct: 0.603515625\n",
            "39: source correct: 0.89912109375, target correct: 0.09951171875\n",
            "40: source correct: 0.88740234375, target correct: 0.10732421875\n",
            "41: source correct: 0.8794921875, target correct: 0.11845703125\n",
            "42: source correct: 0.9015625, target correct: 0.10205078125\n",
            "43: source correct: 0.92294921875, target correct: 0.075390625\n",
            "44: source correct: 0.92431640625, target correct: 0.0708984375\n",
            "45: source correct: 0.89951171875, target correct: 0.1037109375\n",
            "46: source correct: 0.866015625, target correct: 0.13779296875\n",
            "47: source correct: 0.84765625, target correct: 0.14541015625\n",
            "48: source correct: 0.8544921875, target correct: 0.15029296875\n",
            "49: source correct: 0.7287109375, target correct: 0.2720703125\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "dann = DANN().to(device)\n",
        "optimizer = optim.Adam(dann.parameters(), lr=0.001)\n",
        "\n",
        "train_DANN(train_loader, dann, criterion, optimizer, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "51HtQQfPdEq9"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Linear, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear (50 * 4 * 4, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (1000, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (100, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 50 * 4 * 4)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "92iF-iUedEq9"
      },
      "outputs": [],
      "source": [
        "leader = Linear().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(leader.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(testloader, dann, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for a, b in testloader:\n",
        "            a, b = a.to(device), b.to(device)\n",
        "            feature = dann.feature(a)\n",
        "            outputs = leader(feature)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += b.size(0)\n",
        "            correct += (predicted == b).sum().item()\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "VO1DA5C7WFMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "O_TW4WckdEq-",
        "outputId": "60ca9635-0bf9-4df6-b2d9-d58d36652628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 2.3496, test_acc: 0.3816105769230769\n",
            "Epoch [2/30], Loss: 1.4788, test_acc: 0.6490384615384616\n",
            "Epoch [3/30], Loss: 2.3385, test_acc: 0.5740184294871795\n",
            "Epoch [4/30], Loss: 1.9101, test_acc: 0.7028245192307693\n",
            "Epoch [5/30], Loss: 0.9868, test_acc: 0.7924679487179487\n",
            "Epoch [6/30], Loss: 0.5209, test_acc: 0.9236778846153846\n",
            "Epoch [7/30], Loss: 0.3131, test_acc: 0.909354967948718\n",
            "Epoch [8/30], Loss: 0.2191, test_acc: 0.8883213141025641\n",
            "Epoch [9/30], Loss: 0.2190, test_acc: 0.8960336538461539\n",
            "Epoch [10/30], Loss: 0.2195, test_acc: 0.9142628205128205\n",
            "Epoch [11/30], Loss: 0.1343, test_acc: 0.9380008012820513\n",
            "Epoch [12/30], Loss: 0.0939, test_acc: 0.9512219551282052\n",
            "Epoch [13/30], Loss: 0.0690, test_acc: 0.9573317307692307\n",
            "Epoch [14/30], Loss: 0.0337, test_acc: 0.9555288461538461\n",
            "Epoch [15/30], Loss: 0.0581, test_acc: 0.9519230769230769\n"
          ]
        }
      ],
      "source": [
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "for epoch in range(15):\n",
        "    leader.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        feature = dann.feature(images)\n",
        "\n",
        "    outputs = leader(feature)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    with torch.no_grad():\n",
        "        torch.save(leader.state_dict(), f'model_batch_A_{epoch}.pth')\n",
        "\n",
        "    batch_acc = test(testloader, dann, leader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/15], Loss: {loss.item():.4f}, test_acc: {batch_acc}\")\n",
        "\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "for e in range(15):\n",
        "    with torch.no_grad():\n",
        "        feature = dann.feature(images)\n",
        "        new_model = Linear()\n",
        "        new_model.load_state_dict(torch.load(f'model_batch_A_{e}.pth'))\n",
        "        new_model = new_model.to(device)\n",
        "        outputs = new_model(feature)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        batch_acc = test(testloader, dann, new_model)\n",
        "\n",
        "        print(f\"Epoch [{e+1}/15], Loss: {loss.item():.4f}, test_acc: {batch_acc}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}