{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OT8NfOcbkbzR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "import copy\n",
        "from torch.autograd import Function\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-DsLK_NnkbzR"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 256\n",
        "image_size = 28*28\n",
        "alpha = 0.005\n",
        "DANN_EPOCHES = 50\n",
        "DANN_TRAINING_BATCH = 40\n",
        "dann_path = 'dann.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rzl9AkwhkbzR",
        "outputId": "ceec5923-7085-42c8-a3af-c3034d429f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 85835463.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Split training set for training and validation\n",
        "train_size = int(0.8 * len(train_set))\n",
        "val_size = len(train_set) - train_size\n",
        "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "# DataLoader for validation set\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, drop_last = True)\n",
        "train_loader =  DataLoader(train_set, batch_size=256, shuffle=False, drop_last = True)\n",
        "test_loader =  DataLoader(test_set, batch_size=256, shuffle=False, drop_last = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BPHNhlPkbzR"
      },
      "source": [
        "# DANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0CWhtn0jkbzS"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dXz9YIu4kbzS"
      },
      "outputs": [],
      "source": [
        "class DANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DANN, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data, alpha):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 3, 32, 32)\n",
        "        feature = self.feature(input_data)\n",
        "        feature = feature.view(-1, 512)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.classifier(feature)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return class_output, domain_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p38-3bPBkbzS"
      },
      "outputs": [],
      "source": [
        "def train_DANN(train_loader, model, criterion, optimizer, epoches):\n",
        "    model.train()\n",
        "    src_domain_label = torch.ones(batch_size).long().to(device)\n",
        "    tgt_domain_label = torch.zeros(batch_size).long().to(device)\n",
        "\n",
        "    for e in range(epoches):\n",
        "        data_target_iter = iter(train_loader)\n",
        "        correct_source_domain, correct_tgt_domain = 0, 0\n",
        "        total = 0\n",
        "        for i in range(DANN_TRAINING_BATCH):\n",
        "            # Src\n",
        "            source, source_label = next(data_target_iter)\n",
        "            total += source.size(0)\n",
        "\n",
        "            source, source_label = source.to(device), source_label.to(device)\n",
        "\n",
        "            class_output, domain_output = model(source, alpha)\n",
        "\n",
        "            loss_s_label = criterion(class_output, source_label)\n",
        "            loss_s_domain = criterion(domain_output, src_domain_label)\n",
        "\n",
        "            _, predicted = torch.max(domain_output.data, 1)\n",
        "            correct_source_domain += predicted.eq(src_domain_label.data).cpu().sum().item()\n",
        "\n",
        "            # Tgt\n",
        "            target, target_label  = next(data_target_iter)\n",
        "            target, target_label = target.to(device), target_label.to(device)\n",
        "\n",
        "            class_output, domain_output = model(target, alpha)\n",
        "\n",
        "            loss_t_label = criterion(class_output, target_label)\n",
        "            loss_t_domain = criterion(domain_output, tgt_domain_label)\n",
        "\n",
        "            _, predicted = torch.max(domain_output.data, 1)\n",
        "            correct_tgt_domain += predicted.eq(tgt_domain_label.data).cpu().sum().item()\n",
        "\n",
        "            loss = loss_s_label + loss_s_domain + loss_t_domain + loss_t_label\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if ((e + 1) % 5 == 0):\n",
        "            print(f\"{e}: source correct: {correct_source_domain/total}, \\\n",
        "                        target correct: {correct_tgt_domain/total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I6ffFuN6kbzS",
        "outputId": "88381c15-b074-4449-d32d-8b714644a87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4: source correct: 0.94189453125,                         target correct: 0.0453125\n",
            "9: source correct: 0.4751953125,                         target correct: 0.519921875\n",
            "14: source correct: 0.33388671875,                         target correct: 0.69306640625\n",
            "19: source correct: 0.89814453125,                         target correct: 0.104296875\n",
            "24: source correct: 0.03935546875,                         target correct: 0.9677734375\n",
            "29: source correct: 0.990625,                         target correct: 0.0091796875\n",
            "34: source correct: 0.5033203125,                         target correct: 0.4974609375\n",
            "39: source correct: 0.02919921875,                         target correct: 0.9734375\n",
            "44: source correct: 0.983203125,                         target correct: 0.016015625\n",
            "49: source correct: 0.01865234375,                         target correct: 0.98388671875\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(dann_path):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    dann = DANN().to(device)\n",
        "    optimizer = optim.Adam(dann.parameters(), lr=0.001)\n",
        "\n",
        "    train_DANN(train_loader, dann, criterion, optimizer, DANN_EPOCHES)\n",
        "    with torch.no_grad():\n",
        "        torch.save(dann.state_dict(), dann_path)\n",
        "else:\n",
        "    dann = DANN().to(device)\n",
        "    dann.load_state_dict(torch.load(dann_path))\n",
        "    print(\"Loaded model from file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyMOw2MnkbzS"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YUUN_86BkbzS"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Linear, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear (512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (512, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear (100, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 512)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "20aZKkZMkbzS"
      },
      "outputs": [],
      "source": [
        "def test(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, label in testloader:\n",
        "        images, label = images.to(device), label.to(device)\n",
        "        feature = dann.feature(images)\n",
        "        outputs = model(feature)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "er2btBgSkbzS"
      },
      "outputs": [],
      "source": [
        "def train_Linear(model, epoches, criterion, optimizer):\n",
        "    best_model_wts = None\n",
        "    best_loss = float('inf')\n",
        "    batch_num = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        if (best_model_wts):\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        for epoch in range(epoches):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                feature = dann.feature(inputs)\n",
        "\n",
        "            outputs = model(feature)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for val_inputs, val_labels in val_loader:\n",
        "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "                    feature = dann.feature(val_inputs)\n",
        "                    outputs = model(feature)\n",
        "                    batch_loss = criterion(outputs, val_labels)\n",
        "                    val_loss += batch_loss.item()\n",
        "\n",
        "                if val_loss < best_loss:\n",
        "                    best_loss = val_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                test_acc = test(model, test_loader)\n",
        "\n",
        "            print(f\"Batch: {batch_num}, epoch: {epoch}, Train Loss: {loss.item()}, Val Loss: {val_loss}, Test Acc: {test_acc}\")\n",
        "        batch_num += 1\n",
        "\n",
        "    return best_model_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg_kT-NZkbzS",
        "outputId": "71e1541e-83f0-46be-f504-039d129bc2b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, epoch: 0, Train Loss: 2.3941524028778076, Val Loss: 182.83107328414917, Test Acc: 0.09985977564102565\n",
            "Batch: 0, epoch: 1, Train Loss: 4.42768669128418, Val Loss: 209.79903411865234, Test Acc: 0.0999599358974359\n",
            "Batch: 0, epoch: 2, Train Loss: 5.288842678070068, Val Loss: 116.34704685211182, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 3, Train Loss: 2.952768325805664, Val Loss: 105.61661720275879, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 4, Train Loss: 2.7232742309570312, Val Loss: 97.7428023815155, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 5, Train Loss: 2.540764331817627, Val Loss: 94.71563839912415, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 6, Train Loss: 2.4667017459869385, Val Loss: 94.2074568271637, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 7, Train Loss: 2.443727970123291, Val Loss: 93.06195664405823, Test Acc: 0.09985977564102565\n",
            "Batch: 0, epoch: 8, Train Loss: 2.401240348815918, Val Loss: 92.48777365684509, Test Acc: 0.09985977564102565\n",
            "Batch: 0, epoch: 9, Train Loss: 2.372798204421997, Val Loss: 91.79307317733765, Test Acc: 0.09985977564102565\n",
            "Batch: 0, epoch: 10, Train Loss: 2.343986749649048, Val Loss: 91.28081226348877, Test Acc: 0.09985977564102565\n",
            "Batch: 0, epoch: 11, Train Loss: 2.3230783939361572, Val Loss: 90.8981294631958, Test Acc: 0.10857371794871795\n",
            "Batch: 0, epoch: 12, Train Loss: 2.308079957962036, Val Loss: 90.49800634384155, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 13, Train Loss: 2.298656940460205, Val Loss: 90.296865940094, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 14, Train Loss: 2.2946817874908447, Val Loss: 90.17976021766663, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 15, Train Loss: 2.292253017425537, Val Loss: 90.12389707565308, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 16, Train Loss: 2.291499376296997, Val Loss: 90.10204410552979, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 17, Train Loss: 2.2924766540527344, Val Loss: 89.99668669700623, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 18, Train Loss: 2.2921953201293945, Val Loss: 89.81481146812439, Test Acc: 0.10016025641025642\n",
            "Batch: 0, epoch: 19, Train Loss: 2.2903811931610107, Val Loss: 89.6155104637146, Test Acc: 0.10016025641025642\n",
            "Batch: 1, epoch: 0, Train Loss: 2.297373056411743, Val Loss: 89.44815564155579, Test Acc: 0.10176282051282051\n",
            "Batch: 1, epoch: 1, Train Loss: 2.2943921089172363, Val Loss: 89.25803208351135, Test Acc: 0.10366586538461539\n",
            "Batch: 1, epoch: 2, Train Loss: 2.2894680500030518, Val Loss: 89.20089387893677, Test Acc: 0.10176282051282051\n",
            "Batch: 1, epoch: 3, Train Loss: 2.2858822345733643, Val Loss: 89.08479142189026, Test Acc: 0.1015625\n",
            "Batch: 1, epoch: 4, Train Loss: 2.2809536457061768, Val Loss: 88.89680528640747, Test Acc: 0.10276442307692307\n",
            "Batch: 1, epoch: 5, Train Loss: 2.275542974472046, Val Loss: 88.76331973075867, Test Acc: 0.10276442307692307\n",
            "Batch: 1, epoch: 6, Train Loss: 2.2704200744628906, Val Loss: 88.66333246231079, Test Acc: 0.10346554487179487\n",
            "Batch: 1, epoch: 7, Train Loss: 2.264986515045166, Val Loss: 88.37724924087524, Test Acc: 0.10616987179487179\n",
            "Batch: 1, epoch: 8, Train Loss: 2.257622718811035, Val Loss: 88.06828951835632, Test Acc: 0.11157852564102565\n",
            "Batch: 1, epoch: 9, Train Loss: 2.2493863105773926, Val Loss: 87.93577694892883, Test Acc: 0.11348157051282051\n",
            "Batch: 1, epoch: 10, Train Loss: 2.2408652305603027, Val Loss: 87.48085927963257, Test Acc: 0.1162860576923077\n",
            "Batch: 1, epoch: 11, Train Loss: 2.23116135597229, Val Loss: 87.24553203582764, Test Acc: 0.11678685897435898\n",
            "Batch: 1, epoch: 12, Train Loss: 2.2201058864593506, Val Loss: 86.76154232025146, Test Acc: 0.11688701923076923\n",
            "Batch: 1, epoch: 13, Train Loss: 2.2087392807006836, Val Loss: 86.71689248085022, Test Acc: 0.11688701923076923\n",
            "Batch: 1, epoch: 14, Train Loss: 2.1984686851501465, Val Loss: 86.04111361503601, Test Acc: 0.11067708333333333\n",
            "Batch: 1, epoch: 15, Train Loss: 2.192640542984009, Val Loss: 85.86594271659851, Test Acc: 0.12429887820512821\n",
            "Batch: 1, epoch: 16, Train Loss: 2.172513484954834, Val Loss: 85.12400341033936, Test Acc: 0.11959134615384616\n",
            "Batch: 1, epoch: 17, Train Loss: 2.157667636871338, Val Loss: 84.6779043674469, Test Acc: 0.11428285256410256\n",
            "Batch: 1, epoch: 18, Train Loss: 2.1446919441223145, Val Loss: 84.56262373924255, Test Acc: 0.11698717948717949\n",
            "Batch: 1, epoch: 19, Train Loss: 2.132202625274658, Val Loss: 83.68679475784302, Test Acc: 0.15474759615384615\n",
            "Batch: 2, epoch: 0, Train Loss: 2.1415395736694336, Val Loss: 83.52963542938232, Test Acc: 0.18219150641025642\n",
            "Batch: 2, epoch: 1, Train Loss: 2.1238763332366943, Val Loss: 82.37235236167908, Test Acc: 0.19310897435897437\n",
            "Batch: 2, epoch: 2, Train Loss: 2.1027300357818604, Val Loss: 81.95829105377197, Test Acc: 0.19130608974358973\n",
            "Batch: 2, epoch: 3, Train Loss: 2.0786197185516357, Val Loss: 81.29627013206482, Test Acc: 0.18850160256410256\n",
            "Batch: 2, epoch: 4, Train Loss: 2.0576353073120117, Val Loss: 80.28636980056763, Test Acc: 0.19110576923076922\n",
            "Batch: 2, epoch: 5, Train Loss: 2.040977716445923, Val Loss: 80.99376177787781, Test Acc: 0.18279246794871795\n",
            "Batch: 2, epoch: 6, Train Loss: 2.0275354385375977, Val Loss: 79.45851302146912, Test Acc: 0.1974158653846154\n",
            "Batch: 2, epoch: 7, Train Loss: 2.0281665325164795, Val Loss: 80.87694823741913, Test Acc: 0.18739983974358973\n",
            "Batch: 2, epoch: 8, Train Loss: 2.0058910846710205, Val Loss: 78.56541121006012, Test Acc: 0.19631410256410256\n",
            "Batch: 2, epoch: 9, Train Loss: 1.9913249015808105, Val Loss: 78.71343266963959, Test Acc: 0.18709935897435898\n",
            "Batch: 2, epoch: 10, Train Loss: 1.9610995054244995, Val Loss: 78.82460844516754, Test Acc: 0.18259214743589744\n",
            "Batch: 2, epoch: 11, Train Loss: 1.958311915397644, Val Loss: 77.8777242898941, Test Acc: 0.19561298076923078\n",
            "Batch: 2, epoch: 12, Train Loss: 1.974835991859436, Val Loss: 79.78921663761139, Test Acc: 0.1896033653846154\n",
            "Batch: 2, epoch: 13, Train Loss: 1.957145094871521, Val Loss: 78.09131979942322, Test Acc: 0.2038261217948718\n",
            "Batch: 2, epoch: 14, Train Loss: 1.9446240663528442, Val Loss: 77.90768384933472, Test Acc: 0.2072315705128205\n",
            "Batch: 2, epoch: 15, Train Loss: 1.9389863014221191, Val Loss: 79.10508811473846, Test Acc: 0.20112179487179488\n",
            "Batch: 2, epoch: 16, Train Loss: 1.9432320594787598, Val Loss: 76.97600901126862, Test Acc: 0.21013621794871795\n",
            "Batch: 2, epoch: 17, Train Loss: 1.9412074089050293, Val Loss: 77.05637693405151, Test Acc: 0.19841746794871795\n",
            "Batch: 2, epoch: 18, Train Loss: 1.9204422235488892, Val Loss: 78.81403112411499, Test Acc: 0.19561298076923078\n",
            "Batch: 2, epoch: 19, Train Loss: 1.9346826076507568, Val Loss: 77.61147749423981, Test Acc: 0.20202323717948717\n",
            "Batch: 3, epoch: 0, Train Loss: 2.0840749740600586, Val Loss: 79.65400421619415, Test Acc: 0.1801883012820513\n",
            "Batch: 3, epoch: 1, Train Loss: 2.1190967559814453, Val Loss: 78.15006637573242, Test Acc: 0.20582932692307693\n",
            "Batch: 3, epoch: 2, Train Loss: 2.0692434310913086, Val Loss: 77.10552370548248, Test Acc: 0.1935096153846154\n",
            "Batch: 3, epoch: 3, Train Loss: 2.003620147705078, Val Loss: 80.44230329990387, Test Acc: 0.1635616987179487\n",
            "Batch: 3, epoch: 4, Train Loss: 2.0470123291015625, Val Loss: 79.34034597873688, Test Acc: 0.17748397435897437\n",
            "Batch: 3, epoch: 5, Train Loss: 2.001628875732422, Val Loss: 80.92587971687317, Test Acc: 0.1898036858974359\n",
            "Batch: 3, epoch: 6, Train Loss: 2.0297422409057617, Val Loss: 80.08260953426361, Test Acc: 0.20172275641025642\n",
            "Batch: 3, epoch: 7, Train Loss: 1.998604655265808, Val Loss: 80.85954976081848, Test Acc: 0.19631410256410256\n",
            "Batch: 3, epoch: 8, Train Loss: 2.017967700958252, Val Loss: 79.57635521888733, Test Acc: 0.18479567307692307\n",
            "Batch: 3, epoch: 9, Train Loss: 1.9870949983596802, Val Loss: 79.70017409324646, Test Acc: 0.18599759615384615\n",
            "Batch: 3, epoch: 10, Train Loss: 1.9935669898986816, Val Loss: 78.85058164596558, Test Acc: 0.19100560897435898\n",
            "Batch: 3, epoch: 11, Train Loss: 1.9704443216323853, Val Loss: 79.17416155338287, Test Acc: 0.1819911858974359\n",
            "Batch: 3, epoch: 12, Train Loss: 1.982311487197876, Val Loss: 78.32837724685669, Test Acc: 0.18399439102564102\n",
            "Batch: 3, epoch: 13, Train Loss: 1.9644988775253296, Val Loss: 78.23966193199158, Test Acc: 0.18689903846153846\n",
            "Batch: 3, epoch: 14, Train Loss: 1.9683598279953003, Val Loss: 77.81643104553223, Test Acc: 0.1875\n",
            "Batch: 3, epoch: 15, Train Loss: 1.9569488763809204, Val Loss: 78.03123664855957, Test Acc: 0.18940304487179488\n",
            "Batch: 3, epoch: 16, Train Loss: 1.9642417430877686, Val Loss: 77.67777299880981, Test Acc: 0.19290865384615385\n",
            "Batch: 3, epoch: 17, Train Loss: 1.9543931484222412, Val Loss: 77.86922454833984, Test Acc: 0.18860176282051283\n",
            "Batch: 3, epoch: 18, Train Loss: 1.9603888988494873, Val Loss: 77.72236335277557, Test Acc: 0.18890224358974358\n",
            "Batch: 3, epoch: 19, Train Loss: 1.9516328573226929, Val Loss: 78.02965414524078, Test Acc: 0.19681490384615385\n",
            "Batch: 4, epoch: 0, Train Loss: 2.006398916244507, Val Loss: 76.65108859539032, Test Acc: 0.19701522435897437\n",
            "Batch: 4, epoch: 1, Train Loss: 1.985827922821045, Val Loss: 77.0969672203064, Test Acc: 0.1794871794871795\n",
            "Batch: 4, epoch: 2, Train Loss: 1.9776393175125122, Val Loss: 77.30408298969269, Test Acc: 0.17748397435897437\n",
            "Batch: 4, epoch: 3, Train Loss: 1.97113835811615, Val Loss: 76.90587341785431, Test Acc: 0.1780849358974359\n",
            "Batch: 4, epoch: 4, Train Loss: 1.9587377309799194, Val Loss: 76.38210535049438, Test Acc: 0.20452724358974358\n",
            "Batch: 4, epoch: 5, Train Loss: 1.9428619146347046, Val Loss: 76.5323349237442, Test Acc: 0.19671474358974358\n",
            "Batch: 4, epoch: 6, Train Loss: 1.9418524503707886, Val Loss: 76.35364747047424, Test Acc: 0.19641426282051283\n",
            "Batch: 4, epoch: 7, Train Loss: 1.9399607181549072, Val Loss: 76.48979938030243, Test Acc: 0.19611378205128205\n",
            "Batch: 4, epoch: 8, Train Loss: 1.9411249160766602, Val Loss: 76.7695347070694, Test Acc: 0.19100560897435898\n",
            "Batch: 4, epoch: 9, Train Loss: 1.9362800121307373, Val Loss: 76.6265960931778, Test Acc: 0.1762820512820513\n",
            "Batch: 4, epoch: 10, Train Loss: 1.9282505512237549, Val Loss: 76.68908262252808, Test Acc: 0.17638221153846154\n",
            "Batch: 4, epoch: 11, Train Loss: 1.9243988990783691, Val Loss: 76.68717658519745, Test Acc: 0.17317708333333334\n",
            "Batch: 4, epoch: 12, Train Loss: 1.9201629161834717, Val Loss: 76.34594511985779, Test Acc: 0.17307692307692307\n",
            "Batch: 4, epoch: 13, Train Loss: 1.9140602350234985, Val Loss: 76.15308964252472, Test Acc: 0.19140625\n",
            "Batch: 4, epoch: 14, Train Loss: 1.9109302759170532, Val Loss: 76.0820506811142, Test Acc: 0.2029246794871795\n",
            "Batch: 4, epoch: 15, Train Loss: 1.9100041389465332, Val Loss: 76.09782445430756, Test Acc: 0.20402644230769232\n",
            "Batch: 4, epoch: 16, Train Loss: 1.911415457725525, Val Loss: 76.24497520923615, Test Acc: 0.20793269230769232\n",
            "Batch: 4, epoch: 17, Train Loss: 1.9120088815689087, Val Loss: 76.36796021461487, Test Acc: 0.2029246794871795\n",
            "Batch: 4, epoch: 18, Train Loss: 1.9112002849578857, Val Loss: 76.53952348232269, Test Acc: 0.19290865384615385\n",
            "Batch: 4, epoch: 19, Train Loss: 1.910445213317871, Val Loss: 76.68184161186218, Test Acc: 0.1987179487179487\n",
            "Batch: 5, epoch: 0, Train Loss: 1.9446465969085693, Val Loss: 76.35348534584045, Test Acc: 0.20232371794871795\n",
            "Batch: 5, epoch: 1, Train Loss: 1.928220272064209, Val Loss: 76.24200975894928, Test Acc: 0.20993589743589744\n",
            "Batch: 5, epoch: 2, Train Loss: 1.9069350957870483, Val Loss: 76.87972867488861, Test Acc: 0.1994190705128205\n",
            "Batch: 5, epoch: 3, Train Loss: 1.8959541320800781, Val Loss: 77.81329262256622, Test Acc: 0.1798878205128205\n",
            "Batch: 5, epoch: 4, Train Loss: 1.9020110368728638, Val Loss: 78.37679100036621, Test Acc: 0.18369391025641027\n",
            "Batch: 5, epoch: 5, Train Loss: 1.9075219631195068, Val Loss: 78.36729228496552, Test Acc: 0.1778846153846154\n",
            "Batch: 5, epoch: 6, Train Loss: 1.903615117073059, Val Loss: 77.94089591503143, Test Acc: 0.19791666666666666\n",
            "Batch: 5, epoch: 7, Train Loss: 1.8974127769470215, Val Loss: 77.56979656219482, Test Acc: 0.19861778846153846\n",
            "Batch: 5, epoch: 8, Train Loss: 1.8971608877182007, Val Loss: 77.32374095916748, Test Acc: 0.1987179487179487\n",
            "Batch: 5, epoch: 9, Train Loss: 1.899513840675354, Val Loss: 76.93755352497101, Test Acc: 0.2065304487179487\n",
            "Batch: 5, epoch: 10, Train Loss: 1.897714614868164, Val Loss: 76.62344634532928, Test Acc: 0.20232371794871795\n",
            "Batch: 5, epoch: 11, Train Loss: 1.8937010765075684, Val Loss: 76.46719062328339, Test Acc: 0.19881810897435898\n",
            "Batch: 5, epoch: 12, Train Loss: 1.8911877870559692, Val Loss: 76.4787528514862, Test Acc: 0.20072115384615385\n",
            "Batch: 5, epoch: 13, Train Loss: 1.8904019594192505, Val Loss: 76.4453489780426, Test Acc: 0.19411057692307693\n",
            "Batch: 5, epoch: 14, Train Loss: 1.8887276649475098, Val Loss: 76.50786137580872, Test Acc: 0.18669871794871795\n",
            "Batch: 5, epoch: 15, Train Loss: 1.886839747428894, Val Loss: 76.5708521604538, Test Acc: 0.17658253205128205\n",
            "Batch: 5, epoch: 16, Train Loss: 1.8866496086120605, Val Loss: 76.61624050140381, Test Acc: 0.17608173076923078\n",
            "Batch: 5, epoch: 17, Train Loss: 1.8877276182174683, Val Loss: 76.72428011894226, Test Acc: 0.17668269230769232\n",
            "Batch: 5, epoch: 18, Train Loss: 1.8883039951324463, Val Loss: 76.54402899742126, Test Acc: 0.17578125\n",
            "Batch: 5, epoch: 19, Train Loss: 1.8863379955291748, Val Loss: 76.48535752296448, Test Acc: 0.18689903846153846\n",
            "Batch: 6, epoch: 0, Train Loss: 1.9730535745620728, Val Loss: 75.9646863937378, Test Acc: 0.1999198717948718\n",
            "Batch: 6, epoch: 1, Train Loss: 1.9590365886688232, Val Loss: 75.85734045505524, Test Acc: 0.19891826923076922\n",
            "Batch: 6, epoch: 2, Train Loss: 1.9459431171417236, Val Loss: 76.34294700622559, Test Acc: 0.19651442307692307\n",
            "Batch: 6, epoch: 3, Train Loss: 1.9360209703445435, Val Loss: 76.67972040176392, Test Acc: 0.19891826923076922\n",
            "Batch: 6, epoch: 4, Train Loss: 1.9315389394760132, Val Loss: 77.26257240772247, Test Acc: 0.1987179487179487\n",
            "Batch: 6, epoch: 5, Train Loss: 1.9312716722488403, Val Loss: 77.7853387594223, Test Acc: 0.1974158653846154\n",
            "Batch: 6, epoch: 6, Train Loss: 1.9332005977630615, Val Loss: 77.72121000289917, Test Acc: 0.2052283653846154\n",
            "Batch: 6, epoch: 7, Train Loss: 1.9322326183319092, Val Loss: 77.68506038188934, Test Acc: 0.2049278846153846\n",
            "Batch: 6, epoch: 8, Train Loss: 1.9268461465835571, Val Loss: 77.4117066860199, Test Acc: 0.20072115384615385\n",
            "Batch: 6, epoch: 9, Train Loss: 1.922741413116455, Val Loss: 77.01689112186432, Test Acc: 0.1882011217948718\n",
            "Batch: 6, epoch: 10, Train Loss: 1.9213414192199707, Val Loss: 76.90380251407623, Test Acc: 0.1891025641025641\n",
            "Batch: 6, epoch: 11, Train Loss: 1.9193484783172607, Val Loss: 76.39864885807037, Test Acc: 0.19010416666666666\n",
            "Batch: 6, epoch: 12, Train Loss: 1.9164106845855713, Val Loss: 76.22538638114929, Test Acc: 0.1891025641025641\n",
            "Batch: 6, epoch: 13, Train Loss: 1.914432406425476, Val Loss: 76.1572231054306, Test Acc: 0.19050480769230768\n",
            "Batch: 6, epoch: 14, Train Loss: 1.9141592979431152, Val Loss: 76.03271555900574, Test Acc: 0.1916065705128205\n",
            "Batch: 6, epoch: 15, Train Loss: 1.91453218460083, Val Loss: 76.15865218639374, Test Acc: 0.19230769230769232\n",
            "Batch: 6, epoch: 16, Train Loss: 1.914017677307129, Val Loss: 76.0664654970169, Test Acc: 0.19541266025641027\n",
            "Batch: 6, epoch: 17, Train Loss: 1.912683367729187, Val Loss: 76.1196084022522, Test Acc: 0.19751602564102563\n",
            "Batch: 6, epoch: 18, Train Loss: 1.9111518859863281, Val Loss: 76.25059258937836, Test Acc: 0.19841746794871795\n",
            "Batch: 6, epoch: 19, Train Loss: 1.9105972051620483, Val Loss: 76.27114748954773, Test Acc: 0.19781650641025642\n",
            "Batch: 7, epoch: 0, Train Loss: 1.8960130214691162, Val Loss: 75.88067543506622, Test Acc: 0.1987179487179487\n",
            "Batch: 7, epoch: 1, Train Loss: 1.8873441219329834, Val Loss: 76.03055560588837, Test Acc: 0.19631410256410256\n",
            "Batch: 7, epoch: 2, Train Loss: 1.8792930841445923, Val Loss: 76.27472221851349, Test Acc: 0.19501201923076922\n",
            "Batch: 7, epoch: 3, Train Loss: 1.8723100423812866, Val Loss: 76.5270893573761, Test Acc: 0.19491185897435898\n",
            "Batch: 7, epoch: 4, Train Loss: 1.8660941123962402, Val Loss: 76.81496930122375, Test Acc: 0.19571314102564102\n",
            "Batch: 7, epoch: 5, Train Loss: 1.8623554706573486, Val Loss: 77.09770703315735, Test Acc: 0.19561298076923078\n",
            "Batch: 7, epoch: 6, Train Loss: 1.861383080482483, Val Loss: 77.37398552894592, Test Acc: 0.19240785256410256\n",
            "Batch: 7, epoch: 7, Train Loss: 1.8611159324645996, Val Loss: 77.52660846710205, Test Acc: 0.18890224358974358\n",
            "Batch: 7, epoch: 8, Train Loss: 1.8608239889144897, Val Loss: 77.54203343391418, Test Acc: 0.1830929487179487\n",
            "Batch: 7, epoch: 9, Train Loss: 1.8602547645568848, Val Loss: 77.48409152030945, Test Acc: 0.19280849358974358\n",
            "Batch: 7, epoch: 10, Train Loss: 1.858202338218689, Val Loss: 77.2692278623581, Test Acc: 0.19310897435897437\n",
            "Batch: 7, epoch: 11, Train Loss: 1.8546006679534912, Val Loss: 77.08493995666504, Test Acc: 0.19340945512820512\n",
            "Batch: 7, epoch: 12, Train Loss: 1.8509410619735718, Val Loss: 76.9735895395279, Test Acc: 0.1930088141025641\n",
            "Batch: 7, epoch: 13, Train Loss: 1.8484129905700684, Val Loss: 76.89581978321075, Test Acc: 0.1912059294871795\n",
            "Batch: 7, epoch: 14, Train Loss: 1.8469513654708862, Val Loss: 76.92602932453156, Test Acc: 0.19060496794871795\n",
            "Batch: 7, epoch: 15, Train Loss: 1.8462727069854736, Val Loss: 76.91614735126495, Test Acc: 0.18920272435897437\n",
            "Batch: 7, epoch: 16, Train Loss: 1.8457965850830078, Val Loss: 76.95876359939575, Test Acc: 0.19330929487179488\n",
            "Batch: 7, epoch: 17, Train Loss: 1.8457484245300293, Val Loss: 77.06483745574951, Test Acc: 0.1937099358974359\n",
            "Batch: 7, epoch: 18, Train Loss: 1.8456265926361084, Val Loss: 77.12265610694885, Test Acc: 0.18950320512820512\n",
            "Batch: 7, epoch: 19, Train Loss: 1.8448184728622437, Val Loss: 77.22957360744476, Test Acc: 0.1898036858974359\n",
            "Batch: 8, epoch: 0, Train Loss: 1.882086992263794, Val Loss: 75.7657321691513, Test Acc: 0.2065304487179487\n",
            "Batch: 8, epoch: 1, Train Loss: 1.8769344091415405, Val Loss: 75.79413485527039, Test Acc: 0.20663060897435898\n",
            "Batch: 8, epoch: 2, Train Loss: 1.870695948600769, Val Loss: 75.85131621360779, Test Acc: 0.20032051282051283\n",
            "Batch: 8, epoch: 3, Train Loss: 1.8650598526000977, Val Loss: 76.08922505378723, Test Acc: 0.19861778846153846\n",
            "Batch: 8, epoch: 4, Train Loss: 1.8614164590835571, Val Loss: 76.35892987251282, Test Acc: 0.1951121794871795\n",
            "Batch: 8, epoch: 5, Train Loss: 1.8604224920272827, Val Loss: 76.63540661334991, Test Acc: 0.19561298076923078\n",
            "Batch: 8, epoch: 6, Train Loss: 1.8599597215652466, Val Loss: 76.75339078903198, Test Acc: 0.1946113782051282\n",
            "Batch: 8, epoch: 7, Train Loss: 1.8583978414535522, Val Loss: 76.75664901733398, Test Acc: 0.19751602564102563\n",
            "Batch: 8, epoch: 8, Train Loss: 1.855202317237854, Val Loss: 76.62519681453705, Test Acc: 0.1960136217948718\n",
            "Batch: 8, epoch: 9, Train Loss: 1.851677656173706, Val Loss: 76.60696375370026, Test Acc: 0.20622996794871795\n",
            "Batch: 8, epoch: 10, Train Loss: 1.849780797958374, Val Loss: 76.64894080162048, Test Acc: 0.1969150641025641\n",
            "Batch: 8, epoch: 11, Train Loss: 1.8536078929901123, Val Loss: 77.43604445457458, Test Acc: 0.2063301282051282\n",
            "Batch: 8, epoch: 12, Train Loss: 1.8704861402511597, Val Loss: 79.11790215969086, Test Acc: 0.18349358974358973\n",
            "Batch: 8, epoch: 13, Train Loss: 1.9209672212600708, Val Loss: 82.05773770809174, Test Acc: 0.19250801282051283\n",
            "Batch: 8, epoch: 14, Train Loss: 2.000913143157959, Val Loss: 81.64888596534729, Test Acc: 0.17708333333333334\n",
            "Batch: 8, epoch: 15, Train Loss: 1.9827708005905151, Val Loss: 77.41624093055725, Test Acc: 0.20412660256410256\n",
            "Batch: 8, epoch: 16, Train Loss: 1.856858491897583, Val Loss: 77.70705306529999, Test Acc: 0.20172275641025642\n",
            "Batch: 8, epoch: 17, Train Loss: 1.8596491813659668, Val Loss: 80.09393870830536, Test Acc: 0.17708333333333334\n",
            "Batch: 8, epoch: 18, Train Loss: 1.9256943464279175, Val Loss: 77.77145719528198, Test Acc: 0.19260817307692307\n",
            "Batch: 8, epoch: 19, Train Loss: 1.8508516550064087, Val Loss: 77.90401268005371, Test Acc: 0.19230769230769232\n",
            "Batch: 9, epoch: 0, Train Loss: 1.9687403440475464, Val Loss: 76.05933260917664, Test Acc: 0.2015224358974359\n",
            "Batch: 9, epoch: 1, Train Loss: 1.9668033123016357, Val Loss: 75.82082009315491, Test Acc: 0.20072115384615385\n",
            "Batch: 9, epoch: 2, Train Loss: 1.9571317434310913, Val Loss: 76.03681588172913, Test Acc: 0.1971153846153846\n",
            "Batch: 9, epoch: 3, Train Loss: 1.9559563398361206, Val Loss: 76.35970091819763, Test Acc: 0.20562900641025642\n",
            "Batch: 9, epoch: 4, Train Loss: 1.9543012380599976, Val Loss: 76.3049635887146, Test Acc: 0.19811698717948717\n",
            "Batch: 9, epoch: 5, Train Loss: 1.9478050470352173, Val Loss: 76.40618884563446, Test Acc: 0.20602964743589744\n",
            "Batch: 9, epoch: 6, Train Loss: 1.9491935968399048, Val Loss: 76.44377636909485, Test Acc: 0.20352564102564102\n",
            "Batch: 9, epoch: 7, Train Loss: 1.945353388786316, Val Loss: 76.31167566776276, Test Acc: 0.2068309294871795\n",
            "Batch: 9, epoch: 8, Train Loss: 1.9415069818496704, Val Loss: 76.26072680950165, Test Acc: 0.20532852564102563\n",
            "Batch: 9, epoch: 9, Train Loss: 1.9423919916152954, Val Loss: 76.24086284637451, Test Acc: 0.20612980769230768\n",
            "Batch: 9, epoch: 10, Train Loss: 1.9379448890686035, Val Loss: 76.24685788154602, Test Acc: 0.20612980769230768\n",
            "Batch: 9, epoch: 11, Train Loss: 1.9364535808563232, Val Loss: 76.12603199481964, Test Acc: 0.20703125\n",
            "Batch: 9, epoch: 12, Train Loss: 1.9353445768356323, Val Loss: 76.13334572315216, Test Acc: 0.2063301282051282\n",
            "Batch: 9, epoch: 13, Train Loss: 1.930419683456421, Val Loss: 76.23416817188263, Test Acc: 0.20352564102564102\n",
            "Batch: 9, epoch: 14, Train Loss: 1.9295642375946045, Val Loss: 76.18628776073456, Test Acc: 0.20212339743589744\n",
            "Batch: 9, epoch: 15, Train Loss: 1.9288620948791504, Val Loss: 76.22542011737823, Test Acc: 0.1997195512820513\n",
            "Batch: 9, epoch: 16, Train Loss: 1.9266765117645264, Val Loss: 76.31638431549072, Test Acc: 0.19771634615384615\n",
            "Batch: 9, epoch: 17, Train Loss: 1.9265921115875244, Val Loss: 76.22277772426605, Test Acc: 0.19220753205128205\n",
            "Batch: 9, epoch: 18, Train Loss: 1.9256595373153687, Val Loss: 76.27048480510712, Test Acc: 0.19491185897435898\n",
            "Batch: 9, epoch: 19, Train Loss: 1.9235506057739258, Val Loss: 76.3938775062561, Test Acc: 0.19491185897435898\n",
            "Batch: 10, epoch: 0, Train Loss: 1.9058011770248413, Val Loss: 78.81546139717102, Test Acc: 0.18870192307692307\n",
            "Batch: 10, epoch: 1, Train Loss: 1.9100573062896729, Val Loss: 76.49689292907715, Test Acc: 0.19781650641025642\n",
            "Batch: 10, epoch: 2, Train Loss: 1.8798267841339111, Val Loss: 76.0235321521759, Test Acc: 0.20062099358974358\n",
            "Batch: 10, epoch: 3, Train Loss: 1.8919788599014282, Val Loss: 78.15788352489471, Test Acc: 0.19451121794871795\n",
            "Batch: 10, epoch: 4, Train Loss: 1.8776586055755615, Val Loss: 78.22389614582062, Test Acc: 0.19220753205128205\n",
            "Batch: 10, epoch: 5, Train Loss: 1.8718953132629395, Val Loss: 77.05998277664185, Test Acc: 0.20022035256410256\n",
            "Batch: 10, epoch: 6, Train Loss: 1.8812494277954102, Val Loss: 78.54957818984985, Test Acc: 0.19631410256410256\n",
            "Batch: 10, epoch: 7, Train Loss: 1.8682862520217896, Val Loss: 79.2493747472763, Test Acc: 0.19260817307692307\n",
            "Batch: 10, epoch: 8, Train Loss: 1.8716297149658203, Val Loss: 77.36088228225708, Test Acc: 0.20042067307692307\n",
            "Batch: 10, epoch: 9, Train Loss: 1.8723629713058472, Val Loss: 78.0132223367691, Test Acc: 0.19911858974358973\n",
            "Batch: 10, epoch: 10, Train Loss: 1.858741283416748, Val Loss: 78.75075876712799, Test Acc: 0.19541266025641027\n",
            "Batch: 10, epoch: 11, Train Loss: 1.86408531665802, Val Loss: 76.74652314186096, Test Acc: 0.20142227564102563\n",
            "Batch: 10, epoch: 12, Train Loss: 1.8634166717529297, Val Loss: 77.04743218421936, Test Acc: 0.2008213141025641\n",
            "Batch: 10, epoch: 13, Train Loss: 1.854816198348999, Val Loss: 78.71660780906677, Test Acc: 0.19771634615384615\n",
            "Batch: 10, epoch: 14, Train Loss: 1.8649801015853882, Val Loss: 76.59021234512329, Test Acc: 0.2010216346153846\n",
            "Batch: 10, epoch: 15, Train Loss: 1.8579732179641724, Val Loss: 76.7148050069809, Test Acc: 0.20002003205128205\n",
            "Batch: 10, epoch: 16, Train Loss: 1.8545030355453491, Val Loss: 78.70332896709442, Test Acc: 0.1946113782051282\n",
            "Batch: 10, epoch: 17, Train Loss: 1.8635683059692383, Val Loss: 76.76161730289459, Test Acc: 0.20072115384615385\n",
            "Batch: 10, epoch: 18, Train Loss: 1.8551139831542969, Val Loss: 77.07310950756073, Test Acc: 0.20012019230769232\n",
            "Batch: 10, epoch: 19, Train Loss: 1.8519458770751953, Val Loss: 78.76564657688141, Test Acc: 0.1930088141025641\n",
            "Batch: 11, epoch: 0, Train Loss: 1.979380488395691, Val Loss: 76.49498438835144, Test Acc: 0.20512820512820512\n",
            "Batch: 11, epoch: 1, Train Loss: 1.990088701248169, Val Loss: 75.9044440984726, Test Acc: 0.2038261217948718\n",
            "Batch: 11, epoch: 2, Train Loss: 1.9803972244262695, Val Loss: 75.86083018779755, Test Acc: 0.2013221153846154\n",
            "Batch: 11, epoch: 3, Train Loss: 1.972386360168457, Val Loss: 76.59354853630066, Test Acc: 0.19671474358974358\n",
            "Batch: 11, epoch: 4, Train Loss: 1.9791929721832275, Val Loss: 76.12606298923492, Test Acc: 0.18940304487179488\n",
            "Batch: 11, epoch: 5, Train Loss: 1.9691158533096313, Val Loss: 76.24342978000641, Test Acc: 0.1880008012820513\n",
            "Batch: 11, epoch: 6, Train Loss: 1.968284010887146, Val Loss: 76.70971703529358, Test Acc: 0.1893028846153846\n",
            "Batch: 11, epoch: 7, Train Loss: 1.971567153930664, Val Loss: 76.25782942771912, Test Acc: 0.19170673076923078\n",
            "Batch: 11, epoch: 8, Train Loss: 1.9618159532546997, Val Loss: 76.35786664485931, Test Acc: 0.1946113782051282\n",
            "Batch: 11, epoch: 9, Train Loss: 1.9638999700546265, Val Loss: 76.54980897903442, Test Acc: 0.19671474358974358\n",
            "Batch: 11, epoch: 10, Train Loss: 1.9637395143508911, Val Loss: 76.28466081619263, Test Acc: 0.19821714743589744\n",
            "Batch: 11, epoch: 11, Train Loss: 1.9576082229614258, Val Loss: 76.40588116645813, Test Acc: 0.2013221153846154\n",
            "Batch: 11, epoch: 12, Train Loss: 1.9608455896377563, Val Loss: 76.38649225234985, Test Acc: 0.1971153846153846\n",
            "Batch: 11, epoch: 13, Train Loss: 1.9566470384597778, Val Loss: 76.33223795890808, Test Acc: 0.19981971153846154\n",
            "Batch: 11, epoch: 14, Train Loss: 1.9538518190383911, Val Loss: 76.45453894138336, Test Acc: 0.20052083333333334\n",
            "Batch: 11, epoch: 15, Train Loss: 1.9562572240829468, Val Loss: 76.42028510570526, Test Acc: 0.19821714743589744\n",
            "Batch: 11, epoch: 16, Train Loss: 1.952069878578186, Val Loss: 76.5092750787735, Test Acc: 0.1987179487179487\n",
            "Batch: 11, epoch: 17, Train Loss: 1.9521204233169556, Val Loss: 76.54663050174713, Test Acc: 0.20042067307692307\n",
            "Batch: 11, epoch: 18, Train Loss: 1.9524587392807007, Val Loss: 76.50337219238281, Test Acc: 0.19861778846153846\n",
            "Batch: 11, epoch: 19, Train Loss: 1.9492005109786987, Val Loss: 76.60656881332397, Test Acc: 0.19911858974358973\n",
            "Batch: 12, epoch: 0, Train Loss: 1.9686976671218872, Val Loss: 77.40850293636322, Test Acc: 0.19981971153846154\n",
            "Batch: 12, epoch: 1, Train Loss: 1.9755852222442627, Val Loss: 75.90596497058868, Test Acc: 0.21584535256410256\n",
            "Batch: 12, epoch: 2, Train Loss: 1.9520573616027832, Val Loss: 76.13106524944305, Test Acc: 0.2104366987179487\n",
            "Batch: 12, epoch: 3, Train Loss: 1.9462690353393555, Val Loss: 77.91853666305542, Test Acc: 0.20893429487179488\n",
            "Batch: 12, epoch: 4, Train Loss: 1.9538094997406006, Val Loss: 76.76806032657623, Test Acc: 0.19030448717948717\n",
            "Batch: 12, epoch: 5, Train Loss: 1.9427380561828613, Val Loss: 76.96793830394745, Test Acc: 0.1842948717948718\n",
            "Batch: 12, epoch: 6, Train Loss: 1.9433683156967163, Val Loss: 78.30306625366211, Test Acc: 0.19961939102564102\n",
            "Batch: 12, epoch: 7, Train Loss: 1.9483569860458374, Val Loss: 77.03032660484314, Test Acc: 0.1969150641025641\n",
            "Batch: 12, epoch: 8, Train Loss: 1.9376877546310425, Val Loss: 76.88032817840576, Test Acc: 0.20592948717948717\n",
            "Batch: 12, epoch: 9, Train Loss: 1.9359639883041382, Val Loss: 77.69762456417084, Test Acc: 0.20572916666666666\n",
            "Batch: 12, epoch: 10, Train Loss: 1.9390469789505005, Val Loss: 76.53648662567139, Test Acc: 0.20793269230769232\n",
            "Batch: 12, epoch: 11, Train Loss: 1.9308700561523438, Val Loss: 76.33361113071442, Test Acc: 0.21173878205128205\n",
            "Batch: 12, epoch: 12, Train Loss: 1.9299235343933105, Val Loss: 77.07310259342194, Test Acc: 0.20502804487179488\n",
            "Batch: 12, epoch: 13, Train Loss: 1.9317106008529663, Val Loss: 76.2461816072464, Test Acc: 0.21284054487179488\n",
            "Batch: 12, epoch: 14, Train Loss: 1.925370454788208, Val Loss: 76.26209890842438, Test Acc: 0.2102363782051282\n",
            "Batch: 12, epoch: 15, Train Loss: 1.924363613128662, Val Loss: 77.06740808486938, Test Acc: 0.2065304487179487\n",
            "Batch: 12, epoch: 16, Train Loss: 1.9261730909347534, Val Loss: 76.4838330745697, Test Acc: 0.20392628205128205\n",
            "Batch: 12, epoch: 17, Train Loss: 1.92194664478302, Val Loss: 76.53861951828003, Test Acc: 0.20432692307692307\n",
            "Batch: 12, epoch: 18, Train Loss: 1.921256422996521, Val Loss: 77.2044426202774, Test Acc: 0.20302483974358973\n",
            "Batch: 12, epoch: 19, Train Loss: 1.9226253032684326, Val Loss: 76.64070653915405, Test Acc: 0.2063301282051282\n",
            "Batch: 13, epoch: 0, Train Loss: 1.8981112241744995, Val Loss: 77.2111793756485, Test Acc: 0.19451121794871795\n",
            "Batch: 13, epoch: 1, Train Loss: 1.918813943862915, Val Loss: 75.97195649147034, Test Acc: 0.1875\n",
            "Batch: 13, epoch: 2, Train Loss: 1.8953142166137695, Val Loss: 75.8766086101532, Test Acc: 0.1937099358974359\n",
            "Batch: 13, epoch: 3, Train Loss: 1.8805983066558838, Val Loss: 77.05796670913696, Test Acc: 0.19270833333333334\n",
            "Batch: 13, epoch: 4, Train Loss: 1.8958810567855835, Val Loss: 76.20688724517822, Test Acc: 0.19030448717948717\n",
            "Batch: 13, epoch: 5, Train Loss: 1.8816543817520142, Val Loss: 76.19953346252441, Test Acc: 0.1898036858974359\n",
            "Batch: 13, epoch: 6, Train Loss: 1.875633955001831, Val Loss: 77.06366086006165, Test Acc: 0.18850160256410256\n",
            "Batch: 13, epoch: 7, Train Loss: 1.8880677223205566, Val Loss: 76.31303906440735, Test Acc: 0.18990384615384615\n",
            "Batch: 13, epoch: 8, Train Loss: 1.8791229724884033, Val Loss: 76.17056500911713, Test Acc: 0.19681490384615385\n",
            "Batch: 13, epoch: 9, Train Loss: 1.871414065361023, Val Loss: 76.51826977729797, Test Acc: 0.20392628205128205\n",
            "Batch: 13, epoch: 10, Train Loss: 1.8759148120880127, Val Loss: 76.03975868225098, Test Acc: 0.20412660256410256\n",
            "Batch: 13, epoch: 11, Train Loss: 1.8715780973434448, Val Loss: 75.95498180389404, Test Acc: 0.20713141025641027\n",
            "Batch: 13, epoch: 12, Train Loss: 1.866390347480774, Val Loss: 76.09988379478455, Test Acc: 0.20793269230769232\n",
            "Batch: 13, epoch: 13, Train Loss: 1.8678828477859497, Val Loss: 75.86354219913483, Test Acc: 0.1999198717948718\n",
            "Batch: 13, epoch: 14, Train Loss: 1.8670356273651123, Val Loss: 75.91019594669342, Test Acc: 0.2024238782051282\n",
            "Batch: 13, epoch: 15, Train Loss: 1.8644897937774658, Val Loss: 76.12105309963226, Test Acc: 0.20002003205128205\n",
            "Batch: 13, epoch: 16, Train Loss: 1.8655288219451904, Val Loss: 76.00098705291748, Test Acc: 0.19401041666666666\n",
            "Batch: 13, epoch: 17, Train Loss: 1.864024043083191, Val Loss: 76.0920467376709, Test Acc: 0.19561298076923078\n",
            "Batch: 13, epoch: 18, Train Loss: 1.8616636991500854, Val Loss: 76.26045310497284, Test Acc: 0.19821714743589744\n",
            "Batch: 13, epoch: 19, Train Loss: 1.8616352081298828, Val Loss: 76.15742933750153, Test Acc: 0.20182291666666666\n",
            "Batch: 14, epoch: 0, Train Loss: 1.9611573219299316, Val Loss: 77.8301397562027, Test Acc: 0.19911858974358973\n",
            "Batch: 14, epoch: 1, Train Loss: 1.978896975517273, Val Loss: 75.69844710826874, Test Acc: 0.21264022435897437\n",
            "Batch: 14, epoch: 2, Train Loss: 1.9570138454437256, Val Loss: 75.74563825130463, Test Acc: 0.21594551282051283\n",
            "Batch: 14, epoch: 3, Train Loss: 1.9570852518081665, Val Loss: 77.43177223205566, Test Acc: 0.20582932692307693\n",
            "Batch: 14, epoch: 4, Train Loss: 1.9644575119018555, Val Loss: 75.96029388904572, Test Acc: 0.21243990384615385\n",
            "Batch: 14, epoch: 5, Train Loss: 1.9461414813995361, Val Loss: 75.96843647956848, Test Acc: 0.21374198717948717\n",
            "Batch: 14, epoch: 6, Train Loss: 1.9519495964050293, Val Loss: 77.30336999893188, Test Acc: 0.20302483974358973\n",
            "Batch: 14, epoch: 7, Train Loss: 1.9536991119384766, Val Loss: 76.11493170261383, Test Acc: 0.20923477564102563\n",
            "Batch: 14, epoch: 8, Train Loss: 1.939612865447998, Val Loss: 76.00707912445068, Test Acc: 0.21474358974358973\n",
            "Batch: 14, epoch: 9, Train Loss: 1.942327857017517, Val Loss: 76.92499804496765, Test Acc: 0.2063301282051282\n",
            "Batch: 14, epoch: 10, Train Loss: 1.9414887428283691, Val Loss: 76.09212446212769, Test Acc: 0.21314102564102563\n",
            "Batch: 14, epoch: 11, Train Loss: 1.9316937923431396, Val Loss: 75.93928015232086, Test Acc: 0.21264022435897437\n",
            "Batch: 14, epoch: 12, Train Loss: 1.9339126348495483, Val Loss: 76.75104117393494, Test Acc: 0.20783253205128205\n",
            "Batch: 14, epoch: 13, Train Loss: 1.933268666267395, Val Loss: 76.07182765007019, Test Acc: 0.21083733974358973\n",
            "Batch: 14, epoch: 14, Train Loss: 1.9263888597488403, Val Loss: 76.05015826225281, Test Acc: 0.20983573717948717\n",
            "Batch: 14, epoch: 15, Train Loss: 1.9264988899230957, Val Loss: 76.78287839889526, Test Acc: 0.2107371794871795\n",
            "Batch: 14, epoch: 16, Train Loss: 1.9279088973999023, Val Loss: 76.22660207748413, Test Acc: 0.2109375\n",
            "Batch: 14, epoch: 17, Train Loss: 1.923418402671814, Val Loss: 76.33477890491486, Test Acc: 0.21033653846153846\n",
            "Batch: 14, epoch: 18, Train Loss: 1.9214684963226318, Val Loss: 76.88634073734283, Test Acc: 0.20733173076923078\n",
            "Batch: 14, epoch: 19, Train Loss: 1.922379970550537, Val Loss: 76.50890898704529, Test Acc: 0.21223958333333334\n",
            "Batch: 15, epoch: 0, Train Loss: 1.917014718055725, Val Loss: 75.97966063022614, Test Acc: 0.20482772435897437\n",
            "Batch: 15, epoch: 1, Train Loss: 1.9202536344528198, Val Loss: 76.13169860839844, Test Acc: 0.1937099358974359\n",
            "Batch: 15, epoch: 2, Train Loss: 1.9150714874267578, Val Loss: 76.13457870483398, Test Acc: 0.19080528846153846\n",
            "Batch: 15, epoch: 3, Train Loss: 1.9046604633331299, Val Loss: 76.53302609920502, Test Acc: 0.1882011217948718\n",
            "Batch: 15, epoch: 4, Train Loss: 1.907368779182434, Val Loss: 76.67036378383636, Test Acc: 0.1880008012820513\n",
            "Batch: 15, epoch: 5, Train Loss: 1.907453179359436, Val Loss: 76.35557687282562, Test Acc: 0.19170673076923078\n",
            "Batch: 15, epoch: 6, Train Loss: 1.8985854387283325, Val Loss: 76.184561252594, Test Acc: 0.19911858974358973\n",
            "Batch: 15, epoch: 7, Train Loss: 1.8932647705078125, Val Loss: 76.34161150455475, Test Acc: 0.20032051282051283\n",
            "Batch: 15, epoch: 8, Train Loss: 1.896639108657837, Val Loss: 76.38787722587585, Test Acc: 0.20142227564102563\n",
            "Batch: 15, epoch: 9, Train Loss: 1.8947535753250122, Val Loss: 76.17862510681152, Test Acc: 0.19911858974358973\n",
            "Batch: 15, epoch: 10, Train Loss: 1.8870270252227783, Val Loss: 76.16765880584717, Test Acc: 0.19911858974358973\n",
            "Batch: 15, epoch: 11, Train Loss: 1.884767770767212, Val Loss: 76.32879209518433, Test Acc: 0.19981971153846154\n",
            "Batch: 15, epoch: 12, Train Loss: 1.8875261545181274, Val Loss: 76.33074450492859, Test Acc: 0.1958133012820513\n",
            "Batch: 15, epoch: 13, Train Loss: 1.8874242305755615, Val Loss: 76.16652262210846, Test Acc: 0.19571314102564102\n",
            "Batch: 15, epoch: 14, Train Loss: 1.8831850290298462, Val Loss: 76.0024824142456, Test Acc: 0.19140625\n",
            "Batch: 15, epoch: 15, Train Loss: 1.8795065879821777, Val Loss: 76.01341414451599, Test Acc: 0.1919070512820513\n",
            "Batch: 15, epoch: 16, Train Loss: 1.8793785572052002, Val Loss: 76.17302286624908, Test Acc: 0.19861778846153846\n",
            "Batch: 15, epoch: 17, Train Loss: 1.881171703338623, Val Loss: 76.30190432071686, Test Acc: 0.19811698717948717\n",
            "Batch: 15, epoch: 18, Train Loss: 1.8815879821777344, Val Loss: 76.43885600566864, Test Acc: 0.1999198717948718\n",
            "Batch: 15, epoch: 19, Train Loss: 1.8802601099014282, Val Loss: 76.46787738800049, Test Acc: 0.19881810897435898\n",
            "Batch: 16, epoch: 0, Train Loss: 1.9573060274124146, Val Loss: 75.80088472366333, Test Acc: 0.21153846153846154\n",
            "Batch: 16, epoch: 1, Train Loss: 1.9554996490478516, Val Loss: 75.86473631858826, Test Acc: 0.20412660256410256\n",
            "Batch: 16, epoch: 2, Train Loss: 1.9476439952850342, Val Loss: 75.79985082149506, Test Acc: 0.2065304487179487\n",
            "Batch: 16, epoch: 3, Train Loss: 1.9365177154541016, Val Loss: 76.20353782176971, Test Acc: 0.20482772435897437\n",
            "Batch: 16, epoch: 4, Train Loss: 1.936404824256897, Val Loss: 76.48370504379272, Test Acc: 0.20342548076923078\n",
            "Batch: 16, epoch: 5, Train Loss: 1.935205340385437, Val Loss: 76.62544739246368, Test Acc: 0.20282451923076922\n",
            "Batch: 16, epoch: 6, Train Loss: 1.9319870471954346, Val Loss: 76.8444494009018, Test Acc: 0.2036258012820513\n",
            "Batch: 16, epoch: 7, Train Loss: 1.9333616495132446, Val Loss: 76.79055964946747, Test Acc: 0.20322516025641027\n",
            "Batch: 16, epoch: 8, Train Loss: 1.9313393831253052, Val Loss: 76.53638052940369, Test Acc: 0.20372596153846154\n",
            "Batch: 16, epoch: 9, Train Loss: 1.9251599311828613, Val Loss: 76.37478923797607, Test Acc: 0.20643028846153846\n",
            "Batch: 16, epoch: 10, Train Loss: 1.9229459762573242, Val Loss: 76.18703246116638, Test Acc: 0.20983573717948717\n",
            "Batch: 16, epoch: 11, Train Loss: 1.9209803342819214, Val Loss: 76.01277363300323, Test Acc: 0.20923477564102563\n",
            "Batch: 16, epoch: 12, Train Loss: 1.9169577360153198, Val Loss: 75.95206582546234, Test Acc: 0.2086338141025641\n",
            "Batch: 16, epoch: 13, Train Loss: 1.915459394454956, Val Loss: 75.99325108528137, Test Acc: 0.20853365384615385\n",
            "Batch: 16, epoch: 14, Train Loss: 1.916418194770813, Val Loss: 75.96559858322144, Test Acc: 0.20983573717948717\n",
            "Batch: 16, epoch: 15, Train Loss: 1.9141095876693726, Val Loss: 75.96651673316956, Test Acc: 0.20963541666666666\n",
            "Batch: 16, epoch: 16, Train Loss: 1.9116274118423462, Val Loss: 76.08678579330444, Test Acc: 0.2107371794871795\n",
            "Batch: 16, epoch: 17, Train Loss: 1.9112298488616943, Val Loss: 76.23846006393433, Test Acc: 0.2104366987179487\n",
            "Batch: 16, epoch: 18, Train Loss: 1.909938097000122, Val Loss: 76.32088363170624, Test Acc: 0.21193910256410256\n",
            "Batch: 16, epoch: 19, Train Loss: 1.907674789428711, Val Loss: 76.46857690811157, Test Acc: 0.21213942307692307\n",
            "Batch: 17, epoch: 0, Train Loss: 1.954543948173523, Val Loss: 75.79343903064728, Test Acc: 0.2114383012820513\n",
            "Batch: 17, epoch: 1, Train Loss: 1.9482667446136475, Val Loss: 75.71418273448944, Test Acc: 0.203125\n",
            "Batch: 17, epoch: 2, Train Loss: 1.9407802820205688, Val Loss: 76.01797902584076, Test Acc: 0.1958133012820513\n",
            "Batch: 17, epoch: 3, Train Loss: 1.940142035484314, Val Loss: 76.307812333107, Test Acc: 0.19180689102564102\n",
            "Batch: 17, epoch: 4, Train Loss: 1.9363055229187012, Val Loss: 76.21416783332825, Test Acc: 0.19150641025641027\n",
            "Batch: 17, epoch: 5, Train Loss: 1.9291185140609741, Val Loss: 76.28840506076813, Test Acc: 0.2010216346153846\n",
            "Batch: 17, epoch: 6, Train Loss: 1.927619218826294, Val Loss: 76.49441039562225, Test Acc: 0.20282451923076922\n",
            "Batch: 17, epoch: 7, Train Loss: 1.930999755859375, Val Loss: 76.48891270160675, Test Acc: 0.20372596153846154\n",
            "Batch: 17, epoch: 8, Train Loss: 1.9317156076431274, Val Loss: 76.3342969417572, Test Acc: 0.20612980769230768\n",
            "Batch: 17, epoch: 9, Train Loss: 1.9266586303710938, Val Loss: 76.14406216144562, Test Acc: 0.20122195512820512\n",
            "Batch: 17, epoch: 10, Train Loss: 1.921893835067749, Val Loss: 76.10844588279724, Test Acc: 0.19360977564102563\n",
            "Batch: 17, epoch: 11, Train Loss: 1.9219086170196533, Val Loss: 76.12339794635773, Test Acc: 0.18559695512820512\n",
            "Batch: 17, epoch: 12, Train Loss: 1.921697974205017, Val Loss: 75.9662789106369, Test Acc: 0.1916065705128205\n",
            "Batch: 17, epoch: 13, Train Loss: 1.9188923835754395, Val Loss: 75.90698575973511, Test Acc: 0.1930088141025641\n",
            "Batch: 17, epoch: 14, Train Loss: 1.91794753074646, Val Loss: 75.95193207263947, Test Acc: 0.19771634615384615\n",
            "Batch: 17, epoch: 15, Train Loss: 1.9190443754196167, Val Loss: 75.88948202133179, Test Acc: 0.19921875\n",
            "Batch: 17, epoch: 16, Train Loss: 1.9183404445648193, Val Loss: 75.87995886802673, Test Acc: 0.2033253205128205\n",
            "Batch: 17, epoch: 17, Train Loss: 1.916249394416809, Val Loss: 75.89371764659882, Test Acc: 0.20412660256410256\n",
            "Batch: 17, epoch: 18, Train Loss: 1.9148627519607544, Val Loss: 75.98633420467377, Test Acc: 0.20322516025641027\n",
            "Batch: 17, epoch: 19, Train Loss: 1.9143928289413452, Val Loss: 76.14862895011902, Test Acc: 0.19541266025641027\n",
            "Batch: 18, epoch: 0, Train Loss: 2.007916212081909, Val Loss: 77.1644697189331, Test Acc: 0.19260817307692307\n",
            "Batch: 18, epoch: 1, Train Loss: 2.0202977657318115, Val Loss: 75.83481788635254, Test Acc: 0.1916065705128205\n",
            "Batch: 18, epoch: 2, Train Loss: 1.9968509674072266, Val Loss: 76.0762494802475, Test Acc: 0.18970352564102563\n",
            "Batch: 18, epoch: 3, Train Loss: 1.98032546043396, Val Loss: 77.3539479970932, Test Acc: 0.1882011217948718\n",
            "Batch: 18, epoch: 4, Train Loss: 1.989470362663269, Val Loss: 77.22930121421814, Test Acc: 0.19411057692307693\n",
            "Batch: 18, epoch: 5, Train Loss: 1.9892414808273315, Val Loss: 77.50594520568848, Test Acc: 0.19200721153846154\n",
            "Batch: 18, epoch: 6, Train Loss: 1.9819629192352295, Val Loss: 77.67008066177368, Test Acc: 0.19280849358974358\n",
            "Batch: 18, epoch: 7, Train Loss: 1.983367681503296, Val Loss: 77.05139362812042, Test Acc: 0.1951121794871795\n",
            "Batch: 18, epoch: 8, Train Loss: 1.9827040433883667, Val Loss: 76.91295373439789, Test Acc: 0.19230769230769232\n",
            "Batch: 18, epoch: 9, Train Loss: 1.97560453414917, Val Loss: 76.71469712257385, Test Acc: 0.19391025641025642\n",
            "Batch: 18, epoch: 10, Train Loss: 1.9750149250030518, Val Loss: 76.3315144777298, Test Acc: 0.19471153846153846\n",
            "Batch: 18, epoch: 11, Train Loss: 1.9777412414550781, Val Loss: 76.48785531520844, Test Acc: 0.18880208333333334\n",
            "Batch: 18, epoch: 12, Train Loss: 1.975521206855774, Val Loss: 76.26439344882965, Test Acc: 0.18940304487179488\n",
            "Batch: 18, epoch: 13, Train Loss: 1.9736689329147339, Val Loss: 76.01719439029694, Test Acc: 0.19451121794871795\n",
            "Batch: 18, epoch: 14, Train Loss: 1.9735597372055054, Val Loss: 76.13947975635529, Test Acc: 0.1912059294871795\n",
            "Batch: 18, epoch: 15, Train Loss: 1.9703599214553833, Val Loss: 76.32171607017517, Test Acc: 0.1932091346153846\n",
            "Batch: 18, epoch: 16, Train Loss: 1.9701029062271118, Val Loss: 76.08736956119537, Test Acc: 0.19921875\n",
            "Batch: 18, epoch: 17, Train Loss: 1.9702649116516113, Val Loss: 76.36800575256348, Test Acc: 0.19701522435897437\n",
            "Batch: 18, epoch: 18, Train Loss: 1.9677952527999878, Val Loss: 76.52559864521027, Test Acc: 0.1953125\n",
            "Batch: 18, epoch: 19, Train Loss: 1.9679450988769531, Val Loss: 76.41521620750427, Test Acc: 0.19571314102564102\n",
            "Batch: 19, epoch: 0, Train Loss: 1.9720053672790527, Val Loss: 76.78280460834503, Test Acc: 0.1997195512820513\n",
            "Batch: 19, epoch: 1, Train Loss: 1.9693177938461304, Val Loss: 75.87923455238342, Test Acc: 0.1880008012820513\n",
            "Batch: 19, epoch: 2, Train Loss: 1.9545949697494507, Val Loss: 76.19554400444031, Test Acc: 0.18399439102564102\n",
            "Batch: 19, epoch: 3, Train Loss: 1.9505815505981445, Val Loss: 77.47291386127472, Test Acc: 0.18810096153846154\n",
            "Batch: 19, epoch: 4, Train Loss: 1.9566013813018799, Val Loss: 76.6535656452179, Test Acc: 0.19180689102564102\n",
            "Batch: 19, epoch: 5, Train Loss: 1.9518781900405884, Val Loss: 77.0182991027832, Test Acc: 0.20202323717948717\n",
            "Batch: 19, epoch: 6, Train Loss: 1.9442102909088135, Val Loss: 77.24507558345795, Test Acc: 0.2008213141025641\n",
            "Batch: 19, epoch: 7, Train Loss: 1.9442647695541382, Val Loss: 76.71638286113739, Test Acc: 0.2068309294871795\n",
            "Batch: 19, epoch: 8, Train Loss: 1.9443050622940063, Val Loss: 76.97161114215851, Test Acc: 0.19811698717948717\n",
            "Batch: 19, epoch: 9, Train Loss: 1.9377480745315552, Val Loss: 76.58495390415192, Test Acc: 0.20412660256410256\n",
            "Batch: 19, epoch: 10, Train Loss: 1.9335908889770508, Val Loss: 76.21032154560089, Test Acc: 0.20713141025641027\n",
            "Batch: 19, epoch: 11, Train Loss: 1.9348902702331543, Val Loss: 76.67732799053192, Test Acc: 0.20622996794871795\n",
            "Batch: 19, epoch: 12, Train Loss: 1.932996153831482, Val Loss: 76.16229784488678, Test Acc: 0.20763221153846154\n",
            "Batch: 19, epoch: 13, Train Loss: 1.928286075592041, Val Loss: 76.03399801254272, Test Acc: 0.2093349358974359\n",
            "Batch: 19, epoch: 14, Train Loss: 1.9290170669555664, Val Loss: 76.59041166305542, Test Acc: 0.2026241987179487\n",
            "Batch: 19, epoch: 15, Train Loss: 1.9282581806182861, Val Loss: 76.27148616313934, Test Acc: 0.2033253205128205\n",
            "Batch: 19, epoch: 16, Train Loss: 1.925039529800415, Val Loss: 76.25135743618011, Test Acc: 0.19911858974358973\n",
            "Batch: 19, epoch: 17, Train Loss: 1.9252707958221436, Val Loss: 76.86956453323364, Test Acc: 0.19260817307692307\n",
            "Batch: 19, epoch: 18, Train Loss: 1.9245907068252563, Val Loss: 76.58106446266174, Test Acc: 0.19360977564102563\n",
            "Batch: 19, epoch: 19, Train Loss: 1.9219069480895996, Val Loss: 76.66631722450256, Test Acc: 0.19340945512820512\n",
            "Batch: 20, epoch: 0, Train Loss: 1.9533562660217285, Val Loss: 77.42200911045074, Test Acc: 0.20272435897435898\n",
            "Batch: 20, epoch: 1, Train Loss: 1.9589800834655762, Val Loss: 76.02734649181366, Test Acc: 0.20893429487179488\n",
            "Batch: 20, epoch: 2, Train Loss: 1.9385054111480713, Val Loss: 76.73265242576599, Test Acc: 0.19280849358974358\n",
            "Batch: 20, epoch: 3, Train Loss: 1.924099326133728, Val Loss: 78.60374653339386, Test Acc: 0.18890224358974358\n",
            "Batch: 20, epoch: 4, Train Loss: 1.9354385137557983, Val Loss: 77.87345790863037, Test Acc: 0.19170673076923078\n",
            "Batch: 20, epoch: 5, Train Loss: 1.935678243637085, Val Loss: 78.27497482299805, Test Acc: 0.19501201923076922\n",
            "Batch: 20, epoch: 6, Train Loss: 1.9258099794387817, Val Loss: 78.92600548267365, Test Acc: 0.20002003205128205\n",
            "Batch: 20, epoch: 7, Train Loss: 1.9326726198196411, Val Loss: 77.66316294670105, Test Acc: 0.20112179487179488\n",
            "Batch: 20, epoch: 8, Train Loss: 1.9328501224517822, Val Loss: 77.73269283771515, Test Acc: 0.20142227564102563\n",
            "Batch: 20, epoch: 9, Train Loss: 1.9207605123519897, Val Loss: 77.74118840694427, Test Acc: 0.20172275641025642\n",
            "Batch: 20, epoch: 10, Train Loss: 1.9207497835159302, Val Loss: 76.81314432621002, Test Acc: 0.20142227564102563\n",
            "Batch: 20, epoch: 11, Train Loss: 1.9246249198913574, Val Loss: 77.18626058101654, Test Acc: 0.20482772435897437\n",
            "Batch: 20, epoch: 12, Train Loss: 1.9183279275894165, Val Loss: 76.88144481182098, Test Acc: 0.20663060897435898\n",
            "Batch: 20, epoch: 13, Train Loss: 1.9154595136642456, Val Loss: 76.29572355747223, Test Acc: 0.20973557692307693\n",
            "Batch: 20, epoch: 14, Train Loss: 1.9185620546340942, Val Loss: 76.99035692214966, Test Acc: 0.20182291666666666\n",
            "Batch: 20, epoch: 15, Train Loss: 1.9172910451889038, Val Loss: 76.55051493644714, Test Acc: 0.20212339743589744\n",
            "Batch: 20, epoch: 16, Train Loss: 1.9135680198669434, Val Loss: 76.41148853302002, Test Acc: 0.20532852564102563\n",
            "Batch: 20, epoch: 17, Train Loss: 1.915530800819397, Val Loss: 77.35753607749939, Test Acc: 0.20212339743589744\n",
            "Batch: 20, epoch: 18, Train Loss: 1.9159115552902222, Val Loss: 76.70105957984924, Test Acc: 0.20612980769230768\n",
            "Batch: 20, epoch: 19, Train Loss: 1.9105240106582642, Val Loss: 76.70897400379181, Test Acc: 0.20643028846153846\n",
            "Batch: 21, epoch: 0, Train Loss: 1.8955597877502441, Val Loss: 76.6986848115921, Test Acc: 0.20813301282051283\n",
            "Batch: 21, epoch: 1, Train Loss: 1.8957144021987915, Val Loss: 75.92678987979889, Test Acc: 0.1997195512820513\n",
            "Batch: 21, epoch: 2, Train Loss: 1.8839274644851685, Val Loss: 76.08968579769135, Test Acc: 0.19030448717948717\n",
            "Batch: 21, epoch: 3, Train Loss: 1.8833811283111572, Val Loss: 77.03193616867065, Test Acc: 0.1891025641025641\n",
            "Batch: 21, epoch: 4, Train Loss: 1.882045865058899, Val Loss: 76.36873066425323, Test Acc: 0.17938701923076922\n",
            "Batch: 21, epoch: 5, Train Loss: 1.8736073970794678, Val Loss: 76.1714882850647, Test Acc: 0.18209134615384615\n",
            "Batch: 21, epoch: 6, Train Loss: 1.8728978633880615, Val Loss: 76.85334467887878, Test Acc: 0.21594551282051283\n",
            "Batch: 21, epoch: 7, Train Loss: 1.871315836906433, Val Loss: 76.14950883388519, Test Acc: 0.2127403846153846\n",
            "Batch: 21, epoch: 8, Train Loss: 1.864747166633606, Val Loss: 76.09845507144928, Test Acc: 0.21003605769230768\n",
            "Batch: 21, epoch: 9, Train Loss: 1.8624444007873535, Val Loss: 76.72970390319824, Test Acc: 0.21003605769230768\n",
            "Batch: 21, epoch: 10, Train Loss: 1.8620671033859253, Val Loss: 76.07434916496277, Test Acc: 0.20803285256410256\n",
            "Batch: 21, epoch: 11, Train Loss: 1.856910228729248, Val Loss: 76.1854829788208, Test Acc: 0.21193910256410256\n",
            "Batch: 21, epoch: 12, Train Loss: 1.8517467975616455, Val Loss: 76.50712156295776, Test Acc: 0.2146434294871795\n",
            "Batch: 21, epoch: 13, Train Loss: 1.8510541915893555, Val Loss: 76.18445348739624, Test Acc: 0.2116386217948718\n",
            "Batch: 21, epoch: 14, Train Loss: 1.8499277830123901, Val Loss: 76.5268886089325, Test Acc: 0.21394230769230768\n",
            "Batch: 21, epoch: 15, Train Loss: 1.8465646505355835, Val Loss: 76.75508284568787, Test Acc: 0.19591346153846154\n",
            "Batch: 21, epoch: 16, Train Loss: 1.8446656465530396, Val Loss: 76.54943811893463, Test Acc: 0.1921073717948718\n",
            "Batch: 21, epoch: 17, Train Loss: 1.844388484954834, Val Loss: 77.15729594230652, Test Acc: 0.19381009615384615\n",
            "Batch: 21, epoch: 18, Train Loss: 1.8430273532867432, Val Loss: 76.588494181633, Test Acc: 0.1971153846153846\n",
            "Batch: 21, epoch: 19, Train Loss: 1.8400914669036865, Val Loss: 76.86574220657349, Test Acc: 0.21564503205128205\n",
            "Batch: 22, epoch: 0, Train Loss: 2.032550573348999, Val Loss: 85.60354781150818, Test Acc: 0.1583533653846154\n",
            "Batch: 22, epoch: 1, Train Loss: 2.1318297386169434, Val Loss: 76.01546943187714, Test Acc: 0.20572916666666666\n",
            "Batch: 22, epoch: 2, Train Loss: 2.0656678676605225, Val Loss: 75.99886476993561, Test Acc: 0.20402644230769232\n",
            "Batch: 22, epoch: 3, Train Loss: 2.0023086071014404, Val Loss: 83.3647391796112, Test Acc: 0.1686698717948718\n",
            "Batch: 22, epoch: 4, Train Loss: 2.0806117057800293, Val Loss: 75.97252237796783, Test Acc: 0.1798878205128205\n",
            "Batch: 22, epoch: 5, Train Loss: 2.033911943435669, Val Loss: 76.01731562614441, Test Acc: 0.1891025641025641\n",
            "Batch: 22, epoch: 6, Train Loss: 2.0031590461730957, Val Loss: 82.2156765460968, Test Acc: 0.1725761217948718\n",
            "Batch: 22, epoch: 7, Train Loss: 2.052027463912964, Val Loss: 76.00322329998016, Test Acc: 0.20002003205128205\n",
            "Batch: 22, epoch: 8, Train Loss: 1.9915508031845093, Val Loss: 75.82474482059479, Test Acc: 0.20562900641025642\n",
            "Batch: 22, epoch: 9, Train Loss: 2.0079922676086426, Val Loss: 80.267019033432, Test Acc: 0.1700721153846154\n",
            "Batch: 22, epoch: 10, Train Loss: 2.0142452716827393, Val Loss: 77.1598368883133, Test Acc: 0.1898036858974359\n",
            "Batch: 22, epoch: 11, Train Loss: 1.9775701761245728, Val Loss: 75.99217557907104, Test Acc: 0.2093349358974359\n",
            "Batch: 22, epoch: 12, Train Loss: 2.010831117630005, Val Loss: 77.69974172115326, Test Acc: 0.18619791666666666\n",
            "Batch: 22, epoch: 13, Train Loss: 1.9769577980041504, Val Loss: 79.0470654964447, Test Acc: 0.17538060897435898\n",
            "Batch: 22, epoch: 14, Train Loss: 1.9887961149215698, Val Loss: 76.1319169998169, Test Acc: 0.20622996794871795\n",
            "Batch: 22, epoch: 15, Train Loss: 1.984156608581543, Val Loss: 76.43104231357574, Test Acc: 0.2008213141025641\n",
            "Batch: 22, epoch: 16, Train Loss: 1.9726052284240723, Val Loss: 79.49333107471466, Test Acc: 0.1750801282051282\n",
            "Batch: 22, epoch: 17, Train Loss: 1.9880868196487427, Val Loss: 77.2088770866394, Test Acc: 0.19340945512820512\n",
            "Batch: 22, epoch: 18, Train Loss: 1.9664827585220337, Val Loss: 76.49660813808441, Test Acc: 0.20412660256410256\n",
            "Batch: 22, epoch: 19, Train Loss: 1.9836385250091553, Val Loss: 77.93980205059052, Test Acc: 0.18840144230769232\n",
            "Batch: 23, epoch: 0, Train Loss: 1.9031989574432373, Val Loss: 79.7717250585556, Test Acc: 0.18439503205128205\n",
            "Batch: 23, epoch: 1, Train Loss: 1.9605258703231812, Val Loss: 75.92937433719635, Test Acc: 0.20392628205128205\n",
            "Batch: 23, epoch: 2, Train Loss: 1.9057484865188599, Val Loss: 76.23149311542511, Test Acc: 0.203125\n",
            "Batch: 23, epoch: 3, Train Loss: 1.9053744077682495, Val Loss: 79.76347661018372, Test Acc: 0.18139022435897437\n",
            "Batch: 23, epoch: 4, Train Loss: 1.9335306882858276, Val Loss: 76.71310687065125, Test Acc: 0.19811698717948717\n",
            "Batch: 23, epoch: 5, Train Loss: 1.8831701278686523, Val Loss: 77.20517468452454, Test Acc: 0.20052083333333334\n",
            "Batch: 23, epoch: 6, Train Loss: 1.9176181554794312, Val Loss: 78.34927833080292, Test Acc: 0.19180689102564102\n",
            "Batch: 23, epoch: 7, Train Loss: 1.8993169069290161, Val Loss: 77.52614629268646, Test Acc: 0.20052083333333334\n",
            "Batch: 23, epoch: 8, Train Loss: 1.8864567279815674, Val Loss: 76.81995129585266, Test Acc: 0.19811698717948717\n",
            "Batch: 23, epoch: 9, Train Loss: 1.9102158546447754, Val Loss: 76.76060199737549, Test Acc: 0.20402644230769232\n",
            "Batch: 23, epoch: 10, Train Loss: 1.8785606622695923, Val Loss: 78.02953922748566, Test Acc: 0.19861778846153846\n",
            "Batch: 23, epoch: 11, Train Loss: 1.8967534303665161, Val Loss: 76.1272964477539, Test Acc: 0.20202323717948717\n",
            "Batch: 23, epoch: 12, Train Loss: 1.8939563035964966, Val Loss: 75.98751389980316, Test Acc: 0.20452724358974358\n",
            "Batch: 23, epoch: 13, Train Loss: 1.880634069442749, Val Loss: 78.10183358192444, Test Acc: 0.1935096153846154\n",
            "Batch: 23, epoch: 14, Train Loss: 1.899596929550171, Val Loss: 75.93865740299225, Test Acc: 0.20532852564102563\n",
            "Batch: 23, epoch: 15, Train Loss: 1.8760790824890137, Val Loss: 75.93962633609772, Test Acc: 0.2049278846153846\n",
            "Batch: 23, epoch: 16, Train Loss: 1.883620023727417, Val Loss: 77.18210220336914, Test Acc: 0.19661458333333334\n",
            "Batch: 23, epoch: 17, Train Loss: 1.8830026388168335, Val Loss: 76.49950158596039, Test Acc: 0.20112179487179488\n",
            "Batch: 23, epoch: 18, Train Loss: 1.8739161491394043, Val Loss: 76.07618761062622, Test Acc: 0.20512820512820512\n",
            "Batch: 23, epoch: 19, Train Loss: 1.8833004236221313, Val Loss: 76.47442150115967, Test Acc: 0.20452724358974358\n",
            "Batch: 24, epoch: 0, Train Loss: 2.0386104583740234, Val Loss: 77.1979638338089, Test Acc: 0.1994190705128205\n",
            "Batch: 24, epoch: 1, Train Loss: 2.0467476844787598, Val Loss: 77.06088268756866, Test Acc: 0.1711738782051282\n",
            "Batch: 24, epoch: 2, Train Loss: 2.0259592533111572, Val Loss: 77.65454590320587, Test Acc: 0.1736778846153846\n",
            "Batch: 24, epoch: 3, Train Loss: 2.004307508468628, Val Loss: 79.27125668525696, Test Acc: 0.18449519230769232\n",
            "Batch: 24, epoch: 4, Train Loss: 2.0226962566375732, Val Loss: 78.99318647384644, Test Acc: 0.17678285256410256\n",
            "Batch: 24, epoch: 5, Train Loss: 2.027423858642578, Val Loss: 78.45690929889679, Test Acc: 0.19240785256410256\n",
            "Batch: 24, epoch: 6, Train Loss: 2.003319501876831, Val Loss: 78.8665874004364, Test Acc: 0.18189102564102563\n",
            "Batch: 24, epoch: 7, Train Loss: 2.0108251571655273, Val Loss: 77.81132733821869, Test Acc: 0.18669871794871795\n",
            "Batch: 24, epoch: 8, Train Loss: 2.00461745262146, Val Loss: 77.4193549156189, Test Acc: 0.19701522435897437\n",
            "Batch: 24, epoch: 9, Train Loss: 1.9981024265289307, Val Loss: 77.91228139400482, Test Acc: 0.19661458333333334\n",
            "Batch: 24, epoch: 10, Train Loss: 2.0050809383392334, Val Loss: 76.87276005744934, Test Acc: 0.1969150641025641\n",
            "Batch: 24, epoch: 11, Train Loss: 1.989478349685669, Val Loss: 76.87880516052246, Test Acc: 0.18279246794871795\n",
            "Batch: 24, epoch: 12, Train Loss: 1.9922751188278198, Val Loss: 77.17954099178314, Test Acc: 0.17287660256410256\n",
            "Batch: 24, epoch: 13, Train Loss: 1.9881795644760132, Val Loss: 77.18274164199829, Test Acc: 0.16506410256410256\n",
            "Batch: 24, epoch: 14, Train Loss: 1.9863966703414917, Val Loss: 77.0784341096878, Test Acc: 0.16947115384615385\n",
            "Batch: 24, epoch: 15, Train Loss: 1.988362431526184, Val Loss: 77.08559691905975, Test Acc: 0.17127403846153846\n",
            "Batch: 24, epoch: 16, Train Loss: 1.9833550453186035, Val Loss: 77.37944865226746, Test Acc: 0.1819911858974359\n",
            "Batch: 24, epoch: 17, Train Loss: 1.9852571487426758, Val Loss: 77.15956854820251, Test Acc: 0.19441105769230768\n",
            "Batch: 24, epoch: 18, Train Loss: 1.9814682006835938, Val Loss: 77.18566310405731, Test Acc: 0.19621394230769232\n",
            "Batch: 24, epoch: 19, Train Loss: 1.9842010736465454, Val Loss: 77.38838410377502, Test Acc: 0.19571314102564102\n",
            "Batch: 25, epoch: 0, Train Loss: 1.8801488876342773, Val Loss: 79.99821543693542, Test Acc: 0.18760016025641027\n",
            "Batch: 25, epoch: 1, Train Loss: 1.9221245050430298, Val Loss: 75.7588996887207, Test Acc: 0.20612980769230768\n",
            "Batch: 25, epoch: 2, Train Loss: 1.8692951202392578, Val Loss: 75.88417637348175, Test Acc: 0.19491185897435898\n",
            "Batch: 25, epoch: 3, Train Loss: 1.8674888610839844, Val Loss: 79.74234616756439, Test Acc: 0.19591346153846154\n",
            "Batch: 25, epoch: 4, Train Loss: 1.8893173933029175, Val Loss: 76.34396314620972, Test Acc: 0.19561298076923078\n",
            "Batch: 25, epoch: 5, Train Loss: 1.8457077741622925, Val Loss: 76.54795157909393, Test Acc: 0.19541266025641027\n",
            "Batch: 25, epoch: 6, Train Loss: 1.8559142351150513, Val Loss: 79.53657925128937, Test Acc: 0.19681490384615385\n",
            "Batch: 25, epoch: 7, Train Loss: 1.8636045455932617, Val Loss: 77.11891782283783, Test Acc: 0.1997195512820513\n",
            "Batch: 25, epoch: 8, Train Loss: 1.8331944942474365, Val Loss: 76.85383796691895, Test Acc: 0.20162259615384615\n",
            "Batch: 25, epoch: 9, Train Loss: 1.8461244106292725, Val Loss: 78.96068120002747, Test Acc: 0.2008213141025641\n",
            "Batch: 25, epoch: 10, Train Loss: 1.8415946960449219, Val Loss: 77.1175491809845, Test Acc: 0.20412660256410256\n",
            "Batch: 25, epoch: 11, Train Loss: 1.8201754093170166, Val Loss: 76.53554975986481, Test Acc: 0.20693108974358973\n",
            "Batch: 25, epoch: 12, Train Loss: 1.8286293745040894, Val Loss: 77.85115480422974, Test Acc: 0.20482772435897437\n",
            "Batch: 25, epoch: 13, Train Loss: 1.818951964378357, Val Loss: 77.30250358581543, Test Acc: 0.20422676282051283\n",
            "Batch: 25, epoch: 14, Train Loss: 1.811998963356018, Val Loss: 76.40695357322693, Test Acc: 0.2054286858974359\n",
            "Batch: 25, epoch: 15, Train Loss: 1.8179529905319214, Val Loss: 77.46046137809753, Test Acc: 0.20222355769230768\n",
            "Batch: 25, epoch: 16, Train Loss: 1.808633804321289, Val Loss: 77.62881588935852, Test Acc: 0.20252403846153846\n",
            "Batch: 25, epoch: 17, Train Loss: 1.8073391914367676, Val Loss: 76.66417646408081, Test Acc: 0.2033253205128205\n",
            "Batch: 25, epoch: 18, Train Loss: 1.811598777770996, Val Loss: 77.7573264837265, Test Acc: 0.20072115384615385\n",
            "Batch: 25, epoch: 19, Train Loss: 1.8030798435211182, Val Loss: 78.11151456832886, Test Acc: 0.20122195512820512\n",
            "Batch: 26, epoch: 0, Train Loss: 1.9386656284332275, Val Loss: 76.07065451145172, Test Acc: 0.21494391025641027\n",
            "Batch: 26, epoch: 1, Train Loss: 1.93599271774292, Val Loss: 75.79839825630188, Test Acc: 0.19391025641025642\n",
            "Batch: 26, epoch: 2, Train Loss: 1.9273474216461182, Val Loss: 75.96816277503967, Test Acc: 0.17097355769230768\n",
            "Batch: 26, epoch: 3, Train Loss: 1.927692174911499, Val Loss: 76.45299804210663, Test Acc: 0.1677684294871795\n",
            "Batch: 26, epoch: 4, Train Loss: 1.926911473274231, Val Loss: 76.39394128322601, Test Acc: 0.1789863782051282\n",
            "Batch: 26, epoch: 5, Train Loss: 1.9247549772262573, Val Loss: 76.22406554222107, Test Acc: 0.17778445512820512\n",
            "Batch: 26, epoch: 6, Train Loss: 1.9249614477157593, Val Loss: 76.17290449142456, Test Acc: 0.1803886217948718\n",
            "Batch: 26, epoch: 7, Train Loss: 1.921576738357544, Val Loss: 76.18312609195709, Test Acc: 0.19150641025641027\n",
            "Batch: 26, epoch: 8, Train Loss: 1.9203788042068481, Val Loss: 75.86501264572144, Test Acc: 0.19841746794871795\n",
            "Batch: 26, epoch: 9, Train Loss: 1.9180840253829956, Val Loss: 75.97461569309235, Test Acc: 0.1814903846153846\n",
            "Batch: 26, epoch: 10, Train Loss: 1.917404294013977, Val Loss: 76.10941863059998, Test Acc: 0.1828926282051282\n",
            "Batch: 26, epoch: 11, Train Loss: 1.9174251556396484, Val Loss: 75.78359460830688, Test Acc: 0.18459535256410256\n",
            "Batch: 26, epoch: 12, Train Loss: 1.914406180381775, Val Loss: 75.795907497406, Test Acc: 0.20733173076923078\n",
            "Batch: 26, epoch: 13, Train Loss: 1.9126404523849487, Val Loss: 75.92198169231415, Test Acc: 0.20853365384615385\n",
            "Batch: 26, epoch: 14, Train Loss: 1.9122666120529175, Val Loss: 75.8919438123703, Test Acc: 0.20903445512820512\n",
            "Batch: 26, epoch: 15, Train Loss: 1.9105632305145264, Val Loss: 76.06194972991943, Test Acc: 0.18559695512820512\n",
            "Batch: 26, epoch: 16, Train Loss: 1.9093743562698364, Val Loss: 76.22276484966278, Test Acc: 0.17848557692307693\n"
          ]
        }
      ],
      "source": [
        "model = Linear().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "best_model_wts = train_Linear(model, 20, criterion, optimizer)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}