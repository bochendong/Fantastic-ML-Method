{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0k8CX8WlUyJJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_size = 28*28\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "latent_dim = 100\n",
        "num_classes = 10\n",
        "\n",
        "OUTPUT_DIR = \"./data/cgan\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v_chqt4bUyJK"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.mkdir(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GO0q4dZHUyJK"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, image_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, context):\n",
        "        noise = noise.view(-1, latent_dim)\n",
        "        context_feature = self.label_emb(context)\n",
        "        x = torch.cat([noise, context_feature], 1)\n",
        "\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HuCAlexYUyJK"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_size + num_classes, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, context):\n",
        "        img = img.view(-1, image_size)\n",
        "        context_feature = self.label_emb(context)\n",
        "\n",
        "        x = torch.cat((img, context_feature), dim=1)\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tNgVH1tyUyJK"
      },
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Optimizers\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mTmXxFQ4UyJK",
        "outputId": "c4849ac5-a3b1-44da-9f6b-dd1fa4648db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Step [400/468], D Loss: 0.9366745948791504, G Loss: 2.1608455181121826\n",
            "Epoch [2/200], Step [400/468], D Loss: 0.7984415292739868, G Loss: 1.1351810693740845\n",
            "Epoch [3/200], Step [400/468], D Loss: 0.691845178604126, G Loss: 2.7750165462493896\n",
            "Epoch [4/200], Step [400/468], D Loss: 0.1668279469013214, G Loss: 3.363769054412842\n",
            "Epoch [5/200], Step [400/468], D Loss: 0.25167202949523926, G Loss: 5.232165813446045\n",
            "Epoch [6/200], Step [400/468], D Loss: 0.12460343539714813, G Loss: 5.728146553039551\n",
            "Epoch [7/200], Step [400/468], D Loss: 0.16725042462348938, G Loss: 4.162979602813721\n",
            "Epoch [8/200], Step [400/468], D Loss: 0.38697531819343567, G Loss: 5.2110066413879395\n",
            "Epoch [9/200], Step [400/468], D Loss: 0.11041513085365295, G Loss: 5.125596523284912\n",
            "Epoch [10/200], Step [400/468], D Loss: 0.32399511337280273, G Loss: 4.737241268157959\n",
            "Epoch [11/200], Step [400/468], D Loss: 0.33340802788734436, G Loss: 3.6825966835021973\n",
            "Epoch [12/200], Step [400/468], D Loss: 0.18752798438072205, G Loss: 4.879441261291504\n",
            "Epoch [13/200], Step [400/468], D Loss: 0.326810359954834, G Loss: 5.087397575378418\n",
            "Epoch [14/200], Step [400/468], D Loss: 0.33509838581085205, G Loss: 4.030033588409424\n",
            "Epoch [15/200], Step [400/468], D Loss: 0.42888301610946655, G Loss: 3.6393542289733887\n",
            "Epoch [16/200], Step [400/468], D Loss: 0.3243080973625183, G Loss: 3.5923335552215576\n",
            "Epoch [17/200], Step [400/468], D Loss: 0.4932200312614441, G Loss: 3.8868486881256104\n",
            "Epoch [18/200], Step [400/468], D Loss: 0.23875576257705688, G Loss: 3.0531845092773438\n",
            "Epoch [19/200], Step [400/468], D Loss: 0.6280590295791626, G Loss: 3.0545554161071777\n",
            "Epoch [20/200], Step [400/468], D Loss: 0.4400537610054016, G Loss: 3.1234936714172363\n",
            "Epoch [21/200], Step [400/468], D Loss: 0.5256809592247009, G Loss: 3.0089001655578613\n",
            "Epoch [22/200], Step [400/468], D Loss: 0.41309309005737305, G Loss: 2.716154098510742\n",
            "Epoch [23/200], Step [400/468], D Loss: 0.5375842452049255, G Loss: 2.6450912952423096\n",
            "Epoch [24/200], Step [400/468], D Loss: 0.5380852222442627, G Loss: 2.9335479736328125\n",
            "Epoch [25/200], Step [400/468], D Loss: 0.4604659676551819, G Loss: 2.7954800128936768\n",
            "Epoch [26/200], Step [400/468], D Loss: 0.6734191179275513, G Loss: 2.2461116313934326\n",
            "Epoch [27/200], Step [400/468], D Loss: 0.6001070737838745, G Loss: 2.104910135269165\n",
            "Epoch [28/200], Step [400/468], D Loss: 0.8157218098640442, G Loss: 2.210139513015747\n",
            "Epoch [29/200], Step [400/468], D Loss: 0.5602095127105713, G Loss: 2.3333897590637207\n",
            "Epoch [30/200], Step [400/468], D Loss: 0.45298075675964355, G Loss: 2.8453383445739746\n",
            "Epoch [31/200], Step [400/468], D Loss: 0.8553408980369568, G Loss: 1.6969711780548096\n",
            "Epoch [32/200], Step [400/468], D Loss: 0.7746168375015259, G Loss: 2.0635581016540527\n",
            "Epoch [33/200], Step [400/468], D Loss: 0.7124466300010681, G Loss: 1.5065381526947021\n",
            "Epoch [34/200], Step [400/468], D Loss: 0.6283448934555054, G Loss: 1.896881341934204\n",
            "Epoch [35/200], Step [400/468], D Loss: 0.8572208881378174, G Loss: 1.6080658435821533\n",
            "Epoch [36/200], Step [400/468], D Loss: 0.833830714225769, G Loss: 1.6619024276733398\n",
            "Epoch [37/200], Step [400/468], D Loss: 0.8768279552459717, G Loss: 1.6688536405563354\n",
            "Epoch [38/200], Step [400/468], D Loss: 0.7171322107315063, G Loss: 1.9986610412597656\n",
            "Epoch [39/200], Step [400/468], D Loss: 0.7875764966011047, G Loss: 1.546014428138733\n",
            "Epoch [40/200], Step [400/468], D Loss: 0.7558015584945679, G Loss: 1.8203282356262207\n",
            "Epoch [41/200], Step [400/468], D Loss: 0.9994150400161743, G Loss: 1.469132900238037\n",
            "Epoch [42/200], Step [400/468], D Loss: 0.9002646207809448, G Loss: 1.4167687892913818\n",
            "Epoch [43/200], Step [400/468], D Loss: 0.9453873038291931, G Loss: 1.1820415258407593\n",
            "Epoch [44/200], Step [400/468], D Loss: 0.8024686574935913, G Loss: 1.69162917137146\n",
            "Epoch [45/200], Step [400/468], D Loss: 0.9323553442955017, G Loss: 1.582732081413269\n",
            "Epoch [46/200], Step [400/468], D Loss: 0.767754077911377, G Loss: 1.9024420976638794\n",
            "Epoch [47/200], Step [400/468], D Loss: 0.9438585042953491, G Loss: 1.2712013721466064\n",
            "Epoch [48/200], Step [400/468], D Loss: 1.264495611190796, G Loss: 1.6043869256973267\n",
            "Epoch [49/200], Step [400/468], D Loss: 0.9962465763092041, G Loss: 1.2690842151641846\n",
            "Epoch [50/200], Step [400/468], D Loss: 0.8727687001228333, G Loss: 1.428120732307434\n",
            "Epoch [51/200], Step [400/468], D Loss: 1.134455680847168, G Loss: 1.5592896938323975\n",
            "Epoch [52/200], Step [400/468], D Loss: 1.127150297164917, G Loss: 1.296848177909851\n",
            "Epoch [53/200], Step [400/468], D Loss: 0.9403274059295654, G Loss: 1.5450290441513062\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7690e1f798bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_real_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_fake_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        real_images, labels = images.to(device), labels.to(device)\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # --------- Train the Teacher (D) --------- #\n",
        "        d_optimizer.zero_grad()\n",
        "        outputs = discriminator(real_images, labels)\n",
        "        d_real_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_images = generator(z, labels)\n",
        "        outputs = discriminator(fake_images, labels)\n",
        "        d_fake_loss = criterion(outputs, fake_labels)\n",
        "\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # --------- Train the Student (G) --------- #\n",
        "        g_optimizer.zero_grad()\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_images = generator(z, labels)\n",
        "        outputs = discriminator(fake_images, labels)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        if (i+1) % 400 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')\n",
        "\n",
        "    # Save generated images every epoch\n",
        "    save_image(fake_images.reshape(fake_images.size(0), 1, 28, 28), './data/cgan/fake_image-%03d.png' % (epoch+1))\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label in range (10):\n",
        "    z = torch.randn(batch_size, latent_dim).to(device)\n",
        "    fakes_classes = torch.ones(10, device=device, dtype=torch.long) * label\n",
        "    fake_images = generator(z, labels)\n",
        "\n",
        "    save_image(fake_images.reshape(fake_images.size(0), 1, 28, 28), './data/cgan/result-%d.png' % (label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-0.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-1.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-2.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-3.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-4.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-5.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-6.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-7.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-8.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open(OUTPUT_DIR + \"result-9.png\")\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
