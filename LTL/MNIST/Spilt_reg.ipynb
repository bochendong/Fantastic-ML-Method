{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "from os import path\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "repeat = 10\n",
    "epoches = 1\n",
    "alpha = 4\n",
    "pre_heat_batches = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheClassLabel(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that has a quick access to all labels of data.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        super(CacheClassLabel, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.labels = torch.LongTensor(len(dataset)).fill_(-1)\n",
    "        print(dataset.root)\n",
    "        label_cache_filename = dataset.root + '/' +'_'+str(len(dataset))+'.pth'\n",
    "        if path.exists(label_cache_filename):\n",
    "            self.labels = torch.load(label_cache_filename)\n",
    "        else:\n",
    "            for i, data in enumerate(dataset):\n",
    "                self.labels[i] = data[1]\n",
    "            torch.save(self.labels, label_cache_filename)\n",
    "        self.number_classes = len(torch.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        return img, target\n",
    "    \n",
    "class AppendName(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that also return the name of the dataset/task\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, name, first_class_ind=0):\n",
    "        super(AppendName,self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.name = name\n",
    "        self.first_class_ind = first_class_ind  # For remapping the class index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        target = target + self.first_class_ind\n",
    "        return img, target, self.name\n",
    "    \n",
    "class Subclass(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that return the task name and remove the offset of labels (Let the labels start from 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, class_list, remap=True):\n",
    "        '''\n",
    "        :param dataset: (CacheClassLabel)\n",
    "        :param class_list: (list) A list of integers\n",
    "        :param remap: (bool) Ex: remap class [2,4,6 ...] to [0,1,2 ...]\n",
    "        '''\n",
    "        super(Subclass,self).__init__()\n",
    "        assert isinstance(dataset, CacheClassLabel), 'dataset must be wrapped by CacheClassLabel'\n",
    "        self.dataset = dataset\n",
    "        self.class_list = class_list\n",
    "        self.remap = remap\n",
    "        self.indices = []\n",
    "        for c in class_list:\n",
    "            self.indices.extend((dataset.labels==c).nonzero().flatten().tolist())\n",
    "        if remap:\n",
    "            self.class_mapping = {c: i for i, c in enumerate(class_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[self.indices[index]]\n",
    "        if self.remap:\n",
    "            raw_target = target.item() if isinstance(target,torch.Tensor) else target\n",
    "            target = self.class_mapping[raw_target]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitGen(train_dataset, val_dataset, first_split_sz=2, other_split_sz=2, rand_split=False, remap_class=False):\n",
    "    assert train_dataset.number_classes==val_dataset.number_classes,'Train/Val has different number of classes'\n",
    "    num_classes =  train_dataset.number_classes\n",
    "\n",
    "    # Calculate the boundary index of classes for splits\n",
    "    # Ex: [0,2,4,6,8,10] or [0,50,60,70,80,90,100]\n",
    "    split_boundaries = [0, first_split_sz]\n",
    "    while split_boundaries[-1]<num_classes:\n",
    "        split_boundaries.append(split_boundaries[-1]+other_split_sz)\n",
    "    print('split_boundaries:',split_boundaries)\n",
    "    assert split_boundaries[-1]==num_classes,'Invalid split size'\n",
    "\n",
    "    # Assign classes to each splits\n",
    "    # Create the dict: {split_name1:[2,6,7], split_name2:[0,3,9], ...}\n",
    "    if not rand_split:\n",
    "        class_lists = {str(i):list(range(split_boundaries[i-1],split_boundaries[i])) for i in range(1,len(split_boundaries))}\n",
    "    else:\n",
    "        randseq = torch.randperm(num_classes)\n",
    "        class_lists = {str(i):randseq[list(range(split_boundaries[i-1],split_boundaries[i]))].tolist() for i in range(1,len(split_boundaries))}\n",
    "    print(class_lists)\n",
    "\n",
    "    # Generate the dicts of splits\n",
    "    # Ex: {split_name1:dataset_split1, split_name2:dataset_split2, ...}\n",
    "    train_dataset_splits = {}\n",
    "    val_dataset_splits = {}\n",
    "    task_output_space = {}\n",
    "    for name,class_list in class_lists.items():\n",
    "        train_dataset_splits[name] = AppendName(Subclass(train_dataset, class_list, remap_class), name)\n",
    "        val_dataset_splits[name] = AppendName(Subclass(val_dataset, class_list, remap_class), name)\n",
    "        task_output_space[name] = len(class_list)\n",
    "\n",
    "    return train_dataset_splits, val_dataset_splits, task_output_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST(dataroot, train_aug=False):\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Pad(2, fill=0, padding_mode='constant'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    train_transform = val_transform\n",
    "    if train_aug:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=dataroot,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_dataset = CacheClassLabel(train_dataset)\n",
    "\n",
    "    val_dataset = torchvision.datasets.MNIST(\n",
    "        dataroot,\n",
    "        train=False,\n",
    "        transform=val_transform\n",
    "    )\n",
    "    val_dataset = CacheClassLabel(val_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n",
      "./data\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = MNIST('./data', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_boundaries: [0, 2, 4, 6, 8, 10]\n",
      "{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset_splits, val_dataset_splits, task_output_space = SplitGen(train_dataset, val_dataset,\n",
    "                                                                          first_split_sz=2,\n",
    "                                                                          other_split_sz=2,\n",
    "                                                                          rand_split=False,\n",
    "                                                                          remap_class=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, out_dim=10, in_channel=1, img_sz=32, hidden_dim=256):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_dim = in_channel*img_sz*img_sz\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.last = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.linear(x.view(-1,self.in_dim))\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP400():\n",
    "    return MLP(hidden_dim=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = float(self.sum) / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        batch_size = target.size(0)\n",
    "        correct = (predicted == target).sum().item() * 100\n",
    "    return correct / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_acc(output, target, meter):\n",
    "    acc = accuracy(output, target)\n",
    "    meter.update(acc, len(target))\n",
    "    return meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_fn(criterion, preds, targets, valid_out_dim):\n",
    "    if valid_out_dim != 0:\n",
    "        pred = preds[:,:valid_out_dim]\n",
    "    loss = criterion(pred, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_task(model, train_loader, optimizer, criterion, \n",
    "                  valid_out_dim, best_model_wts, task_num, task_names):\n",
    "    leader = MLP400().to(device)\n",
    "    best_loss = float('inf')\n",
    "    best_pre_heat_loss = float('inf')\n",
    "    if (best_model_wts):\n",
    "        leader.load_state_dict(best_model_wts)\n",
    "    else:\n",
    "        leader.load_state_dict(model.state_dict())\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        train_acc = AverageMeter()\n",
    "        batch_num = 0\n",
    "        for images, labels, _ in train_loader:\n",
    "            model.train()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                leader_outputs = leader(images)\n",
    "\n",
    "            follower_outputs = model(images)\n",
    "            \n",
    "            c_loss = criterion_fn(criterion, follower_outputs, labels, valid_out_dim)\n",
    "            loss = c_loss + alpha * torch.mean(torch.abs(follower_outputs - leader_outputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc = accumulate_acc(follower_outputs, labels, train_acc)\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = AverageMeter()\n",
    "\n",
    "                for task in range(task_num + 1):\n",
    "                    val_name = task_names[task]\n",
    "                    val_data = val_dataset_splits[val_name]\n",
    "                    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                    for i, (input, target, _) in enumerate(val_loader):\n",
    "                        input, target = input.to(device), target.to(device)\n",
    "                        output = model(input)\n",
    "                        loss_v = criterion(output, target).item()\n",
    "\n",
    "                        val_loss.update(loss_v, len(target))\n",
    "\n",
    "                print(f\"batch_num: {batch_num}, c_loss:{c_loss.item():.4f}, val_loss:{val_loss.avg: .4f}, loss:{loss:.4f}\", end = \" \")\n",
    "                \n",
    "                # 在预热阶段选择接班人\n",
    "                if(batch_num < pre_heat_batches):\n",
    "                    if (val_loss.avg < best_pre_heat_loss):\n",
    "                        best_pre_heat_loss = val_loss.avg\n",
    "                        best_pre_heat_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    print()\n",
    "                # 预热阶段结束，leader 换为接班人\n",
    "                elif (batch_num == pre_heat_batches):\n",
    "                    best_model_wts = best_pre_heat_model_wts\n",
    "                    best_loss = best_pre_heat_loss\n",
    "                    print(f\"Leader changed with val acc {best_loss: .4f}\")\n",
    "                    leader.load_state_dict(best_model_wts) \n",
    "                else:\n",
    "                    if val_loss.avg < best_loss:\n",
    "                        best_loss = val_loss.avg\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                        print(f\"Leader changed with val acc {best_loss: .4f}\")\n",
    "                        leader.load_state_dict(best_model_wts) \n",
    "                    else:\n",
    "                        print()\n",
    "            batch_num += 1\n",
    "    return best_model_wts, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(acc_table, model, train_name, task_names, task_index):\n",
    "    acc_table[train_name] = OrderedDict()\n",
    "\n",
    "    for j in range(task_index+1):\n",
    "        val_name = task_names[j]\n",
    "        val_data = val_dataset_splits[val_name]\n",
    "        val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "        model.eval()\n",
    "        val_acc = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target, _) in enumerate(val_loader):\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    output = model(input)\n",
    "                    val_acc = accumulate_acc(output, target, val_acc)\n",
    "\n",
    "        acc_table[val_name][train_name] = val_acc.avg\n",
    "    \n",
    "    return acc_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(task_names):\n",
    "    leader_acc_table = OrderedDict()\n",
    "    follower_acc_table = OrderedDict()\n",
    "    valid_out_dim = 0\n",
    "\n",
    "    model = MLP400().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.0005)\n",
    "\n",
    "    best_model_wts = None\n",
    "    best_loss = float('inf')\n",
    "    for i in range(len(task_names)):\n",
    "        valid_out_dim += 2\n",
    "        train_name = task_names[i]\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset_splits[train_name], batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f'=====Task: {train_name}=====')\n",
    "        best_model_wts, best_loss = train_on_task(model, train_loader, optimizer, criterion, valid_out_dim, best_model_wts, i, task_names)\n",
    "    \n",
    "        follower_acc_table[train_name] = OrderedDict()\n",
    "\n",
    "        leader = MLP400().to(device)\n",
    "        leader.load_state_dict(best_model_wts)\n",
    "        eval(follower_acc_table, model, train_name, task_names, i)\n",
    "        eval(leader_acc_table, leader, train_name, task_names, i )\n",
    "\n",
    "        print(follower_acc_table)\n",
    "        print(leader_acc_table)\n",
    "\n",
    "    avg_acc_history = [0] * len(task_names)\n",
    "    for i in range(len(task_names)):\n",
    "        train_name = task_names[i]\n",
    "        cls_acc_sum = 0\n",
    "        for j in range(i + 1):\n",
    "            val_name = task_names[j]\n",
    "            cls_acc_sum += follower_acc_table[val_name][train_name]\n",
    "\n",
    "        avg_acc_history[i] = cls_acc_sum / (i + 1)\n",
    "        print('follower Task', train_name, 'average acc:', avg_acc_history[i])\n",
    "    \n",
    "    leader_avg_acc_history = [0] * len(task_names)\n",
    "    for i in range(len(task_names)):\n",
    "        train_name = task_names[i]\n",
    "        cls_acc_sum = 0\n",
    "        for j in range(i + 1):\n",
    "            val_name = task_names[j]\n",
    "            cls_acc_sum += leader_acc_table[val_name][train_name]\n",
    "\n",
    "        leader_avg_acc_history[i] = cls_acc_sum / (i + 1)\n",
    "        print('leader Task', train_name, 'average acc:', leader_avg_acc_history[i])\n",
    "    \n",
    "    return avg_acc_history, leader_avg_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task order: ['1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "task_names = sorted(list(task_output_space.keys()), key=int)\n",
    "print('Task order:',task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Task: 1=====\n",
      "batch_num: 0, c_loss:0.7938, val_loss: 2.1829, loss:0.7938 \n",
      "batch_num: 1, c_loss:0.1841, val_loss: 2.1594, loss:1.2258 \n",
      "batch_num: 2, c_loss:0.1633, val_loss: 2.1502, loss:1.5119 \n",
      "batch_num: 3, c_loss:0.1856, val_loss: 2.1516, loss:1.3864 \n",
      "batch_num: 4, c_loss:0.2190, val_loss: 2.1670, loss:1.2231 \n",
      "batch_num: 5, c_loss:0.3347, val_loss: 2.1939, loss:1.2929 \n",
      "batch_num: 6, c_loss:0.3758, val_loss: 2.2226, loss:1.1871 \n",
      "batch_num: 7, c_loss:0.4907, val_loss: 2.2430, loss:1.1480 \n",
      "batch_num: 8, c_loss:0.5682, val_loss: 2.2537, loss:1.1865 \n",
      "batch_num: 9, c_loss:0.5833, val_loss: 2.2528, loss:1.1216 \n",
      "batch_num: 10, c_loss:0.5858, val_loss: 2.2324, loss:1.1849 \n",
      "batch_num: 11, c_loss:0.5441, val_loss: 2.2077, loss:1.1554 \n",
      "batch_num: 12, c_loss:0.5226, val_loss: 2.1808, loss:1.1476 \n",
      "batch_num: 13, c_loss:0.4538, val_loss: 2.1577, loss:1.1350 \n",
      "batch_num: 14, c_loss:0.4371, val_loss: 2.1382, loss:1.1284 \n",
      "batch_num: 15, c_loss:0.3924, val_loss: 2.1223, loss:1.1121 \n",
      "batch_num: 16, c_loss:0.4083, val_loss: 2.1205, loss:1.1227 \n",
      "batch_num: 17, c_loss:0.4123, val_loss: 2.1236, loss:1.1101 \n",
      "batch_num: 18, c_loss:0.3869, val_loss: 2.1352, loss:1.0637 \n",
      "batch_num: 19, c_loss:0.3991, val_loss: 2.1475, loss:1.0831 \n",
      "batch_num: 20, c_loss:0.4189, val_loss: 2.1588, loss:1.0933 \n",
      "batch_num: 21, c_loss:0.4349, val_loss: 2.1643, loss:1.0925 \n",
      "batch_num: 22, c_loss:0.4550, val_loss: 2.1654, loss:1.0585 \n",
      "batch_num: 23, c_loss:0.4698, val_loss: 2.1646, loss:1.0751 \n",
      "batch_num: 24, c_loss:0.4850, val_loss: 2.1569, loss:1.0803 \n",
      "batch_num: 25, c_loss:0.5042, val_loss: 2.1533, loss:1.1153 \n",
      "batch_num: 26, c_loss:0.4860, val_loss: 2.1551, loss:1.0739 \n",
      "batch_num: 27, c_loss:0.4965, val_loss: 2.1569, loss:1.0774 \n",
      "batch_num: 28, c_loss:0.4859, val_loss: 2.1511, loss:1.0561 \n",
      "batch_num: 29, c_loss:0.4797, val_loss: 2.1418, loss:1.0098 \n",
      "batch_num: 30, c_loss:0.4707, val_loss: 2.1328, loss:1.0465 Leader changed with val acc  2.1205\n",
      "batch_num: 31, c_loss:0.4716, val_loss: 2.0446, loss:0.9494 Leader changed with val acc  2.0446\n",
      "batch_num: 32, c_loss:0.4098, val_loss: 1.9266, loss:0.4098 Leader changed with val acc  1.9266\n",
      "batch_num: 33, c_loss:0.3301, val_loss: 1.7917, loss:0.3301 Leader changed with val acc  1.7917\n",
      "batch_num: 34, c_loss:0.2791, val_loss: 1.6494, loss:0.2791 Leader changed with val acc  1.6494\n",
      "batch_num: 35, c_loss:0.2251, val_loss: 1.5037, loss:0.2251 Leader changed with val acc  1.5037\n",
      "batch_num: 36, c_loss:0.1679, val_loss: 1.3673, loss:0.1679 Leader changed with val acc  1.3673\n",
      "batch_num: 37, c_loss:0.1476, val_loss: 1.2396, loss:0.1476 Leader changed with val acc  1.2396\n",
      "batch_num: 38, c_loss:0.1149, val_loss: 1.1210, loss:0.1149 Leader changed with val acc  1.1210\n",
      "batch_num: 39, c_loss:0.0917, val_loss: 1.0141, loss:0.0917 Leader changed with val acc  1.0141\n",
      "batch_num: 40, c_loss:0.0697, val_loss: 0.9246, loss:0.0697 Leader changed with val acc  0.9246\n",
      "batch_num: 41, c_loss:0.0621, val_loss: 0.8449, loss:0.0621 Leader changed with val acc  0.8449\n",
      "batch_num: 42, c_loss:0.0602, val_loss: 0.7772, loss:0.0602 Leader changed with val acc  0.7772\n",
      "batch_num: 43, c_loss:0.0522, val_loss: 0.7199, loss:0.0522 Leader changed with val acc  0.7199\n",
      "batch_num: 44, c_loss:0.0504, val_loss: 0.6691, loss:0.0504 Leader changed with val acc  0.6691\n",
      "batch_num: 45, c_loss:0.0320, val_loss: 0.6267, loss:0.0320 Leader changed with val acc  0.6267\n",
      "batch_num: 46, c_loss:0.0371, val_loss: 0.5909, loss:0.0371 Leader changed with val acc  0.5909\n",
      "batch_num: 47, c_loss:0.0286, val_loss: 0.5624, loss:0.0286 Leader changed with val acc  0.5624\n",
      "batch_num: 48, c_loss:0.0432, val_loss: 0.5416, loss:0.0432 Leader changed with val acc  0.5416\n",
      "batch_num: 49, c_loss:0.0447, val_loss: 0.5194, loss:0.0447 Leader changed with val acc  0.5194\n",
      "batch_num: 50, c_loss:0.0225, val_loss: 0.5044, loss:0.0225 Leader changed with val acc  0.5044\n",
      "batch_num: 51, c_loss:0.0211, val_loss: 0.4892, loss:0.0211 Leader changed with val acc  0.4892\n",
      "batch_num: 52, c_loss:0.0161, val_loss: 0.4784, loss:0.0161 Leader changed with val acc  0.4784\n",
      "batch_num: 53, c_loss:0.0278, val_loss: 0.4693, loss:0.0278 Leader changed with val acc  0.4693\n",
      "batch_num: 54, c_loss:0.0168, val_loss: 0.4593, loss:0.0168 Leader changed with val acc  0.4593\n",
      "batch_num: 55, c_loss:0.0143, val_loss: 0.4548, loss:0.0143 Leader changed with val acc  0.4548\n",
      "batch_num: 56, c_loss:0.0166, val_loss: 0.4450, loss:0.0166 Leader changed with val acc  0.4450\n",
      "batch_num: 57, c_loss:0.0232, val_loss: 0.4398, loss:0.0232 Leader changed with val acc  0.4398\n",
      "batch_num: 58, c_loss:0.0185, val_loss: 0.4354, loss:0.0185 Leader changed with val acc  0.4354\n",
      "batch_num: 59, c_loss:0.0105, val_loss: 0.4336, loss:0.0105 Leader changed with val acc  0.4336\n",
      "batch_num: 60, c_loss:0.0204, val_loss: 0.4306, loss:0.0204 Leader changed with val acc  0.4306\n",
      "batch_num: 61, c_loss:0.0154, val_loss: 0.4270, loss:0.0154 Leader changed with val acc  0.4270\n",
      "batch_num: 62, c_loss:0.0217, val_loss: 0.4237, loss:0.0217 Leader changed with val acc  0.4237\n",
      "batch_num: 63, c_loss:0.0203, val_loss: 0.4213, loss:0.0203 Leader changed with val acc  0.4213\n",
      "batch_num: 64, c_loss:0.0133, val_loss: 0.4192, loss:0.0133 Leader changed with val acc  0.4192\n",
      "batch_num: 65, c_loss:0.0129, val_loss: 0.4185, loss:0.0129 Leader changed with val acc  0.4185\n",
      "batch_num: 66, c_loss:0.0139, val_loss: 0.4179, loss:0.0139 Leader changed with val acc  0.4179\n",
      "batch_num: 67, c_loss:0.0150, val_loss: 0.4175, loss:0.0150 Leader changed with val acc  0.4175\n",
      "batch_num: 68, c_loss:0.0165, val_loss: 0.4144, loss:0.0165 Leader changed with val acc  0.4144\n",
      "batch_num: 69, c_loss:0.0075, val_loss: 0.4176, loss:0.0075 \n",
      "batch_num: 70, c_loss:0.0106, val_loss: 0.4486, loss:0.0264 \n",
      "batch_num: 71, c_loss:0.0072, val_loss: 0.4524, loss:0.1350 \n",
      "batch_num: 72, c_loss:0.0179, val_loss: 0.4202, loss:0.1172 \n",
      "batch_num: 73, c_loss:0.0117, val_loss: 0.4167, loss:0.1351 \n",
      "batch_num: 74, c_loss:0.0076, val_loss: 0.4360, loss:0.1496 \n",
      "batch_num: 75, c_loss:0.0101, val_loss: 0.4586, loss:0.1329 \n",
      "batch_num: 76, c_loss:0.0092, val_loss: 0.4741, loss:0.1365 \n",
      "batch_num: 77, c_loss:0.0110, val_loss: 0.4710, loss:0.1593 \n",
      "batch_num: 78, c_loss:0.0107, val_loss: 0.4600, loss:0.1524 \n",
      "batch_num: 79, c_loss:0.0365, val_loss: 0.4573, loss:0.1759 \n",
      "batch_num: 80, c_loss:0.0101, val_loss: 0.4765, loss:0.1605 \n",
      "batch_num: 81, c_loss:0.0078, val_loss: 0.4960, loss:0.1564 \n",
      "batch_num: 82, c_loss:0.0085, val_loss: 0.5027, loss:0.1546 \n",
      "batch_num: 83, c_loss:0.0094, val_loss: 0.4988, loss:0.1587 \n",
      "batch_num: 84, c_loss:0.0084, val_loss: 0.4891, loss:0.1499 \n",
      "batch_num: 85, c_loss:0.0130, val_loss: 0.4844, loss:0.1737 \n",
      "batch_num: 86, c_loss:0.0201, val_loss: 0.4887, loss:0.1705 \n",
      "batch_num: 87, c_loss:0.0129, val_loss: 0.4980, loss:0.1596 \n",
      "batch_num: 88, c_loss:0.0123, val_loss: 0.4990, loss:0.1728 \n",
      "batch_num: 89, c_loss:0.0125, val_loss: 0.5052, loss:0.1645 \n",
      "batch_num: 90, c_loss:0.0075, val_loss: 0.5038, loss:0.1519 \n",
      "batch_num: 91, c_loss:0.0098, val_loss: 0.4974, loss:0.1761 \n",
      "batch_num: 92, c_loss:0.0095, val_loss: 0.4821, loss:0.1670 \n",
      "batch_num: 93, c_loss:0.0065, val_loss: 0.4815, loss:0.1593 \n",
      "batch_num: 94, c_loss:0.0087, val_loss: 0.4847, loss:0.1631 \n",
      "batch_num: 95, c_loss:0.0104, val_loss: 0.4950, loss:0.1704 \n",
      "batch_num: 96, c_loss:0.0170, val_loss: 0.5081, loss:0.1904 \n",
      "batch_num: 97, c_loss:0.0102, val_loss: 0.5080, loss:0.1752 \n",
      "batch_num: 98, c_loss:0.0107, val_loss: 0.5080, loss:0.1752 \n",
      "OrderedDict([('1', OrderedDict([('1', 99.81087470449172)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.81087470449172)]))])\n",
      "=====Task: 2=====\n",
      "batch_num: 0, c_loss:1.8786, val_loss: 1.3337, loss:2.1012 \n",
      "batch_num: 1, c_loss:1.7828, val_loss: 1.2973, loss:2.0197 \n",
      "batch_num: 2, c_loss:1.5651, val_loss: 1.2602, loss:1.9172 \n",
      "batch_num: 3, c_loss:1.4634, val_loss: 1.2250, loss:1.9569 \n",
      "batch_num: 4, c_loss:1.2623, val_loss: 1.1951, loss:1.8572 \n",
      "batch_num: 5, c_loss:1.1212, val_loss: 1.1718, loss:1.7923 \n",
      "batch_num: 6, c_loss:1.0644, val_loss: 1.1566, loss:1.8208 \n",
      "batch_num: 7, c_loss:1.0692, val_loss: 1.1486, loss:1.8881 \n",
      "batch_num: 8, c_loss:0.9012, val_loss: 1.1460, loss:1.7937 \n",
      "batch_num: 9, c_loss:0.8764, val_loss: 1.1460, loss:1.8301 \n",
      "batch_num: 10, c_loss:0.7888, val_loss: 1.1477, loss:1.8001 \n",
      "batch_num: 11, c_loss:0.7376, val_loss: 1.1510, loss:1.8016 \n"
     ]
    }
   ],
   "source": [
    "avg_acc_history,leader_avg_acc_history = train(task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nimport torch.nn as nn\\nimport torchvision\\nimport os\\nfrom os import path\\nimport copy\\nimport numpy as np\\nimport torch.utils.data as data\\nfrom torchvision import transforms\\nfrom collections import OrderedDict\\n\\nbatch_size = 128\\nrepeat = 10\\nepoches = 1\\nalpha = 4\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\nclass CacheClassLabel(data.Dataset):\\n    \"\"\"\\n    A dataset wrapper that has a quick access to all labels of data.\\n    \"\"\"\\n    def __init__(self, dataset):\\n        super(CacheClassLabel, self).__init__()\\n        self.dataset = dataset\\n        self.labels = torch.LongTensor(len(dataset)).fill_(-1)\\n        print(dataset.root)\\n        label_cache_filename = dataset.root + \\'/\\' +\\'_\\'+str(len(dataset))+\\'.pth\\'\\n        if path.exists(label_cache_filename):\\n            self.labels = torch.load(label_cache_filename)\\n        else:\\n            for i, data in enumerate(dataset):\\n                self.labels[i] = data[1]\\n            torch.save(self.labels, label_cache_filename)\\n        self.number_classes = len(torch.unique(self.labels))\\n\\n    def __len__(self):\\n        return len(self.dataset)\\n\\n    def __getitem__(self, index):\\n        img,target = self.dataset[index]\\n        return img, target\\n    \\nclass AppendName(data.Dataset):\\n    \"\"\"\\n    A dataset wrapper that also return the name of the dataset/task\\n    \"\"\"\\n    def __init__(self, dataset, name, first_class_ind=0):\\n        super(AppendName,self).__init__()\\n        self.dataset = dataset\\n        self.name = name\\n        self.first_class_ind = first_class_ind  # For remapping the class index\\n\\n    def __len__(self):\\n        return len(self.dataset)\\n\\n    def __getitem__(self, index):\\n        img,target = self.dataset[index]\\n        target = target + self.first_class_ind\\n        return img, target, self.name\\n    \\nclass Subclass(data.Dataset):\\n    \"\"\"\\n    A dataset wrapper that return the task name and remove the offset of labels (Let the labels start from 0)\\n    \"\"\"\\n    def __init__(self, dataset, class_list, remap=True):\\n        super(Subclass,self).__init__()\\n        assert isinstance(dataset, CacheClassLabel), \\'dataset must be wrapped by CacheClassLabel\\'\\n        self.dataset = dataset\\n        self.class_list = class_list\\n        self.remap = remap\\n        self.indices = []\\n        for c in class_list:\\n            self.indices.extend((dataset.labels==c).nonzero().flatten().tolist())\\n        if remap:\\n            self.class_mapping = {c: i for i, c in enumerate(class_list)}\\n\\n    def __len__(self):\\n        return len(self.indices)\\n    def __getitem__(self, index):\\n        img,target = self.dataset[self.indices[index]]\\n        if self.remap:\\n            raw_target = target.item() if isinstance(target,torch.Tensor) else target\\n            target = self.class_mapping[raw_target]\\n        return img, target\\n\\ndef SplitGen(train_dataset, val_dataset, first_split_sz=2, other_split_sz=2, rand_split=False, remap_class=False):\\n    assert train_dataset.number_classes==val_dataset.number_classes,\\'Train/Val has different number of classes\\'\\n    num_classes =  train_dataset.number_classes\\n\\n    # Calculate the boundary index of classes for splits\\n    # Ex: [0,2,4,6,8,10] or [0,50,60,70,80,90,100]\\n    split_boundaries = [0, first_split_sz]\\n    while split_boundaries[-1]<num_classes:\\n        split_boundaries.append(split_boundaries[-1]+other_split_sz)\\n    print(\\'split_boundaries:\\',split_boundaries)\\n    assert split_boundaries[-1]==num_classes,\\'Invalid split size\\'\\n\\n    # Assign classes to each splits\\n    # Create the dict: {split_name1:[2,6,7], split_name2:[0,3,9], ...}\\n    if not rand_split:\\n        class_lists = {str(i):list(range(split_boundaries[i-1],split_boundaries[i])) for i in range(1,len(split_boundaries))}\\n    else:\\n        randseq = torch.randperm(num_classes)\\n        class_lists = {str(i):randseq[list(range(split_boundaries[i-1],split_boundaries[i]))].tolist() for i in range(1,len(split_boundaries))}\\n    print(class_lists)\\n\\n    # Generate the dicts of splits\\n    # Ex: {split_name1:dataset_split1, split_name2:dataset_split2, ...}\\n    train_dataset_splits = {}\\n    val_dataset_splits = {}\\n    task_output_space = {}\\n    for name,class_list in class_lists.items():\\n        train_dataset_splits[name] = AppendName(Subclass(train_dataset, class_list, remap_class), name)\\n        val_dataset_splits[name] = AppendName(Subclass(val_dataset, class_list, remap_class), name)\\n        task_output_space[name] = len(class_list)\\n\\n    return train_dataset_splits, val_dataset_splits, task_output_space\\n\\ndef MNIST(dataroot, train_aug=False):\\n    val_transform = transforms.Compose([\\n        transforms.Pad(2, fill=0, padding_mode=\\'constant\\'),\\n        transforms.ToTensor(),\\n        transforms.Normalize([0.5], [0.5]),\\n    ])\\n    train_transform = val_transform\\n    if train_aug:\\n        train_transform = transforms.Compose([\\n            transforms.ToTensor(),\\n            transforms.Normalize([0.5], [0.5]),\\n        ])\\n\\n    train_dataset = torchvision.datasets.MNIST(\\n        root=dataroot,\\n        train=True,\\n        download=True,\\n        transform=train_transform\\n    )\\n    train_dataset = CacheClassLabel(train_dataset)\\n\\n    val_dataset = torchvision.datasets.MNIST(\\n        dataroot,\\n        train=False,\\n        transform=val_transform\\n    )\\n    val_dataset = CacheClassLabel(val_dataset)\\n\\n    return train_dataset, val_dataset\\n\\ntrain_dataset, val_dataset = MNIST(\\'./data\\', False)\\n\\ntrain_dataset_splits, val_dataset_splits, task_output_space = SplitGen(train_dataset, val_dataset,\\n                                                                          first_split_sz=2,\\n                                                                          other_split_sz=2,\\n                                                                          rand_split=False,\\n                                                                          remap_class=False)\\n\\nclass MLP(nn.Module):\\n    def __init__(self, out_dim=10, in_channel=1, img_sz=32, hidden_dim=256):\\n        super(MLP, self).__init__()\\n        self.in_dim = in_channel*img_sz*img_sz\\n        self.linear = nn.Sequential(\\n            nn.Linear(self.in_dim, hidden_dim),\\n            nn.BatchNorm1d(hidden_dim),\\n            nn.ReLU(inplace=True),\\n            nn.Linear(hidden_dim, hidden_dim),\\n            nn.BatchNorm1d(hidden_dim),\\n            nn.ReLU(inplace=True),\\n        )\\n        self.last = nn.Linear(hidden_dim, out_dim)\\n\\n    def features(self, x):\\n        x = self.linear(x.view(-1,self.in_dim))\\n        return x\\n\\n    def logits(self, x):\\n        x = self.last(x)\\n        return x\\n\\n    def forward(self, x):\\n        x = self.features(x)\\n        x = self.logits(x)\\n        return x\\n\\ndef MLP400():\\n    return MLP(hidden_dim=400)\\n\\nclass AverageMeter(object):\\n    def __init__(self):\\n        self.reset()\\n\\n    def reset(self):\\n        self.val = 0\\n        self.avg = 0\\n        self.sum = 0\\n        self.count = 0\\n\\n    def update(self, val, n=1):\\n        self.val = val\\n        self.sum += val * n\\n        self.count += n\\n        self.avg = float(self.sum) / self.count\\n\\ndef accuracy(output, target):\\n    with torch.no_grad():\\n        _, predicted = torch.max(output.data, 1)\\n        batch_size = target.size(0)\\n        correct = (predicted == target).sum().item() * 100\\n    return correct / batch_size\\n\\ndef accumulate_acc(output, target, meter):\\n    acc = accuracy(output, target)\\n    meter.update(acc, len(target))\\n    return meter\\n\\ndef criterion_fn(criterion, preds, targets, valid_out_dim):\\n    if valid_out_dim != 0:\\n        pred = preds[:,:valid_out_dim]\\n    loss = criterion(pred, targets)\\n    return loss\\n\\ndef train_on_task(model, train_loader, optimizer, criterion, \\n                  valid_out_dim, best_model_wts, task_num, task_names):\\n    leader = MLP400().to(device)\\n    best_loss = float(\\'inf\\')\\n    if (best_model_wts):\\n        leader.load_state_dict(best_model_wts)\\n\\n    for epoch in range(epoches):\\n        train_acc = AverageMeter()\\n        batch_num = 0\\n        for images, labels, _ in train_loader:\\n            images, labels = images.to(device), labels.to(device)\\n\\n            with torch.no_grad():\\n                leader_outputs = leader(images)\\n\\n            model.train()\\n            follower_outputs = model(images)\\n\\n            # reg_loss = 0\\n            # for lead_para, follower_para in zip(leader.parameters(), model.parameters()):\\n                # reg_loss += torch.norm(follower_para - lead_para, p = 2)\\n            \\n            c_loss = criterion_fn(criterion, follower_outputs, labels, valid_out_dim)\\n            loss = c_loss + alpha * torch.mean((follower_outputs - leader_outputs) ** 2)\\n\\n            optimizer.zero_grad()\\n            loss.backward()\\n            optimizer.step()\\n\\n            train_acc = accumulate_acc(follower_outputs, labels, train_acc)\\n            \\n            model.eval()\\n            with torch.no_grad():\\n                val_loss = AverageMeter()\\n\\n                for task in range(task_num + 1):\\n                    val_name = task_names[task]\\n                    val_data = val_dataset_splits[val_name]\\n                    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\\n\\n                    for i, (input, target, _) in enumerate(val_loader):\\n                        input, target = input.to(device), target.to(device)\\n                        output = model(input)\\n                        loss_v = criterion(output, target).item()\\n\\n                        val_loss.update(loss_v, len(target))\\n\\n                    if val_loss.avg < best_loss:\\n                        best_loss = val_loss.avg\\n                        best_model_wts = copy.deepcopy(model.state_dict())\\n                        leader.load_state_dict(best_model_wts) \\n            print(f\"batch_num: {batch_num}, c_loss:{c_loss.item():.4f}, val_loss:{val_loss.avg: .4f}, loss:{loss_v:.4f}\")\\n            batch_num += 1\\n    return best_model_wts, best_loss\\n\\ndef train(task_names):\\n    acc_table = OrderedDict()\\n    valid_out_dim = 0\\n\\n    model = MLP400().to(device)\\n    criterion = nn.CrossEntropyLoss()\\n    optimizer = torch.optim.Adam(model.parameters(), 0.0005)\\n\\n    best_model_wts = None\\n    for i in range(len(task_names)):\\n        valid_out_dim += 2\\n        train_name = task_names[i]\\n        train_loader = torch.utils.data.DataLoader(train_dataset_splits[train_name], batch_size=batch_size, shuffle=True)\\n        \\n        print(f\\'=====Task: {train_name}=====\\')\\n        best_model_wts, best_loss = train_on_task(model, train_loader, optimizer, criterion, valid_out_dim, best_model_wts, i, task_names)\\n    \\n        acc_table[train_name] = OrderedDict()\\n\\n        for j in range(i+1):\\n            val_name = task_names[j]\\n            val_data = val_dataset_splits[val_name]\\n            val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\\n            model.eval()\\n            val_acc = AverageMeter()\\n            with torch.no_grad():\\n                for i, (input, target, _) in enumerate(val_loader):\\n                    input, target = input.to(device), target.to(device)\\n                    output = model(input)\\n                    val_acc = accumulate_acc(output, target, val_acc)\\n\\n            acc_table[val_name][train_name] = val_acc.avg\\n\\n        print(acc_table)\\n\\n    avg_acc_history = [0] * len(task_names)\\n    for i in range(len(task_names)):\\n        train_name = task_names[i]\\n        cls_acc_sum = 0\\n        for j in range(i + 1):\\n            val_name = task_names[j]\\n            cls_acc_sum += acc_table[val_name][train_name]\\n\\n        avg_acc_history[i] = cls_acc_sum / (i + 1)\\n        print(\\'Task\\', train_name, \\'average acc:\\', avg_acc_history[i])\\n    \\n    return avg_acc_history\\n\\ntask_names = sorted(list(task_output_space.keys()), key=int)\\nprint(\\'Task order:\\',task_names)\\n\\navg_acc_history = train(task_names)\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "from os import path\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = 128\n",
    "repeat = 10\n",
    "epoches = 1\n",
    "alpha = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CacheClassLabel(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that has a quick access to all labels of data.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        super(CacheClassLabel, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.labels = torch.LongTensor(len(dataset)).fill_(-1)\n",
    "        print(dataset.root)\n",
    "        label_cache_filename = dataset.root + '/' +'_'+str(len(dataset))+'.pth'\n",
    "        if path.exists(label_cache_filename):\n",
    "            self.labels = torch.load(label_cache_filename)\n",
    "        else:\n",
    "            for i, data in enumerate(dataset):\n",
    "                self.labels[i] = data[1]\n",
    "            torch.save(self.labels, label_cache_filename)\n",
    "        self.number_classes = len(torch.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        return img, target\n",
    "    \n",
    "class AppendName(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that also return the name of the dataset/task\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, name, first_class_ind=0):\n",
    "        super(AppendName,self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.name = name\n",
    "        self.first_class_ind = first_class_ind  # For remapping the class index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        target = target + self.first_class_ind\n",
    "        return img, target, self.name\n",
    "    \n",
    "class Subclass(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that return the task name and remove the offset of labels (Let the labels start from 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, class_list, remap=True):\n",
    "        super(Subclass,self).__init__()\n",
    "        assert isinstance(dataset, CacheClassLabel), 'dataset must be wrapped by CacheClassLabel'\n",
    "        self.dataset = dataset\n",
    "        self.class_list = class_list\n",
    "        self.remap = remap\n",
    "        self.indices = []\n",
    "        for c in class_list:\n",
    "            self.indices.extend((dataset.labels==c).nonzero().flatten().tolist())\n",
    "        if remap:\n",
    "            self.class_mapping = {c: i for i, c in enumerate(class_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[self.indices[index]]\n",
    "        if self.remap:\n",
    "            raw_target = target.item() if isinstance(target,torch.Tensor) else target\n",
    "            target = self.class_mapping[raw_target]\n",
    "        return img, target\n",
    "\n",
    "def SplitGen(train_dataset, val_dataset, first_split_sz=2, other_split_sz=2, rand_split=False, remap_class=False):\n",
    "    assert train_dataset.number_classes==val_dataset.number_classes,'Train/Val has different number of classes'\n",
    "    num_classes =  train_dataset.number_classes\n",
    "\n",
    "    # Calculate the boundary index of classes for splits\n",
    "    # Ex: [0,2,4,6,8,10] or [0,50,60,70,80,90,100]\n",
    "    split_boundaries = [0, first_split_sz]\n",
    "    while split_boundaries[-1]<num_classes:\n",
    "        split_boundaries.append(split_boundaries[-1]+other_split_sz)\n",
    "    print('split_boundaries:',split_boundaries)\n",
    "    assert split_boundaries[-1]==num_classes,'Invalid split size'\n",
    "\n",
    "    # Assign classes to each splits\n",
    "    # Create the dict: {split_name1:[2,6,7], split_name2:[0,3,9], ...}\n",
    "    if not rand_split:\n",
    "        class_lists = {str(i):list(range(split_boundaries[i-1],split_boundaries[i])) for i in range(1,len(split_boundaries))}\n",
    "    else:\n",
    "        randseq = torch.randperm(num_classes)\n",
    "        class_lists = {str(i):randseq[list(range(split_boundaries[i-1],split_boundaries[i]))].tolist() for i in range(1,len(split_boundaries))}\n",
    "    print(class_lists)\n",
    "\n",
    "    # Generate the dicts of splits\n",
    "    # Ex: {split_name1:dataset_split1, split_name2:dataset_split2, ...}\n",
    "    train_dataset_splits = {}\n",
    "    val_dataset_splits = {}\n",
    "    task_output_space = {}\n",
    "    for name,class_list in class_lists.items():\n",
    "        train_dataset_splits[name] = AppendName(Subclass(train_dataset, class_list, remap_class), name)\n",
    "        val_dataset_splits[name] = AppendName(Subclass(val_dataset, class_list, remap_class), name)\n",
    "        task_output_space[name] = len(class_list)\n",
    "\n",
    "    return train_dataset_splits, val_dataset_splits, task_output_space\n",
    "\n",
    "def MNIST(dataroot, train_aug=False):\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Pad(2, fill=0, padding_mode='constant'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    train_transform = val_transform\n",
    "    if train_aug:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=dataroot,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_dataset = CacheClassLabel(train_dataset)\n",
    "\n",
    "    val_dataset = torchvision.datasets.MNIST(\n",
    "        dataroot,\n",
    "        train=False,\n",
    "        transform=val_transform\n",
    "    )\n",
    "    val_dataset = CacheClassLabel(val_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "train_dataset, val_dataset = MNIST('./data', False)\n",
    "\n",
    "train_dataset_splits, val_dataset_splits, task_output_space = SplitGen(train_dataset, val_dataset,\n",
    "                                                                          first_split_sz=2,\n",
    "                                                                          other_split_sz=2,\n",
    "                                                                          rand_split=False,\n",
    "                                                                          remap_class=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, out_dim=10, in_channel=1, img_sz=32, hidden_dim=256):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_dim = in_channel*img_sz*img_sz\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.last = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.linear(x.view(-1,self.in_dim))\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "def MLP400():\n",
    "    return MLP(hidden_dim=400)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = float(self.sum) / self.count\n",
    "\n",
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        batch_size = target.size(0)\n",
    "        correct = (predicted == target).sum().item() * 100\n",
    "    return correct / batch_size\n",
    "\n",
    "def accumulate_acc(output, target, meter):\n",
    "    acc = accuracy(output, target)\n",
    "    meter.update(acc, len(target))\n",
    "    return meter\n",
    "\n",
    "def criterion_fn(criterion, preds, targets, valid_out_dim):\n",
    "    if valid_out_dim != 0:\n",
    "        pred = preds[:,:valid_out_dim]\n",
    "    loss = criterion(pred, targets)\n",
    "    return loss\n",
    "\n",
    "def train_on_task(model, train_loader, optimizer, criterion, \n",
    "                  valid_out_dim, best_model_wts, task_num, task_names):\n",
    "    leader = MLP400().to(device)\n",
    "    best_loss = float('inf')\n",
    "    if (best_model_wts):\n",
    "        leader.load_state_dict(best_model_wts)\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        train_acc = AverageMeter()\n",
    "        batch_num = 0\n",
    "        for images, labels, _ in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                leader_outputs = leader(images)\n",
    "\n",
    "            model.train()\n",
    "            follower_outputs = model(images)\n",
    "\n",
    "            # reg_loss = 0\n",
    "            # for lead_para, follower_para in zip(leader.parameters(), model.parameters()):\n",
    "                # reg_loss += torch.norm(follower_para - lead_para, p = 2)\n",
    "            \n",
    "            c_loss = criterion_fn(criterion, follower_outputs, labels, valid_out_dim)\n",
    "            loss = c_loss + alpha * torch.mean((follower_outputs - leader_outputs) ** 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc = accumulate_acc(follower_outputs, labels, train_acc)\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = AverageMeter()\n",
    "\n",
    "                for task in range(task_num + 1):\n",
    "                    val_name = task_names[task]\n",
    "                    val_data = val_dataset_splits[val_name]\n",
    "                    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                    for i, (input, target, _) in enumerate(val_loader):\n",
    "                        input, target = input.to(device), target.to(device)\n",
    "                        output = model(input)\n",
    "                        loss_v = criterion(output, target).item()\n",
    "\n",
    "                        val_loss.update(loss_v, len(target))\n",
    "\n",
    "                    if val_loss.avg < best_loss:\n",
    "                        best_loss = val_loss.avg\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                        leader.load_state_dict(best_model_wts) \n",
    "            print(f\"batch_num: {batch_num}, c_loss:{c_loss.item():.4f}, val_loss:{val_loss.avg: .4f}, loss:{loss_v:.4f}\")\n",
    "            batch_num += 1\n",
    "    return best_model_wts, best_loss\n",
    "\n",
    "def train(task_names):\n",
    "    acc_table = OrderedDict()\n",
    "    valid_out_dim = 0\n",
    "\n",
    "    model = MLP400().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.0005)\n",
    "\n",
    "    best_model_wts = None\n",
    "    for i in range(len(task_names)):\n",
    "        valid_out_dim += 2\n",
    "        train_name = task_names[i]\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset_splits[train_name], batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f'=====Task: {train_name}=====')\n",
    "        best_model_wts, best_loss = train_on_task(model, train_loader, optimizer, criterion, valid_out_dim, best_model_wts, i, task_names)\n",
    "    \n",
    "        acc_table[train_name] = OrderedDict()\n",
    "\n",
    "        for j in range(i+1):\n",
    "            val_name = task_names[j]\n",
    "            val_data = val_dataset_splits[val_name]\n",
    "            val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "            model.eval()\n",
    "            val_acc = AverageMeter()\n",
    "            with torch.no_grad():\n",
    "                for i, (input, target, _) in enumerate(val_loader):\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    output = model(input)\n",
    "                    val_acc = accumulate_acc(output, target, val_acc)\n",
    "\n",
    "            acc_table[val_name][train_name] = val_acc.avg\n",
    "\n",
    "        print(acc_table)\n",
    "\n",
    "    avg_acc_history = [0] * len(task_names)\n",
    "    for i in range(len(task_names)):\n",
    "        train_name = task_names[i]\n",
    "        cls_acc_sum = 0\n",
    "        for j in range(i + 1):\n",
    "            val_name = task_names[j]\n",
    "            cls_acc_sum += acc_table[val_name][train_name]\n",
    "\n",
    "        avg_acc_history[i] = cls_acc_sum / (i + 1)\n",
    "        print('Task', train_name, 'average acc:', avg_acc_history[i])\n",
    "    \n",
    "    return avg_acc_history\n",
    "\n",
    "task_names = sorted(list(task_output_space.keys()), key=int)\n",
    "print('Task order:',task_names)\n",
    "\n",
    "avg_acc_history = train(task_names)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
