{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "from os import path\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "repeat = 10\n",
    "epoches = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheClassLabel(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that has a quick access to all labels of data.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        super(CacheClassLabel, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.labels = torch.LongTensor(len(dataset)).fill_(-1)\n",
    "        print(dataset.root)\n",
    "        label_cache_filename = dataset.root + '/' +'_'+str(len(dataset))+'.pth'\n",
    "        if path.exists(label_cache_filename):\n",
    "            self.labels = torch.load(label_cache_filename)\n",
    "        else:\n",
    "            for i, data in enumerate(dataset):\n",
    "                self.labels[i] = data[1]\n",
    "            torch.save(self.labels, label_cache_filename)\n",
    "        self.number_classes = len(torch.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        return img, target\n",
    "    \n",
    "class AppendName(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that also return the name of the dataset/task\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, name, first_class_ind=0):\n",
    "        super(AppendName,self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.name = name\n",
    "        self.first_class_ind = first_class_ind  # For remapping the class index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[index]\n",
    "        target = target + self.first_class_ind\n",
    "        return img, target, self.name\n",
    "    \n",
    "class Subclass(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset wrapper that return the task name and remove the offset of labels (Let the labels start from 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, class_list, remap=True):\n",
    "        '''\n",
    "        :param dataset: (CacheClassLabel)\n",
    "        :param class_list: (list) A list of integers\n",
    "        :param remap: (bool) Ex: remap class [2,4,6 ...] to [0,1,2 ...]\n",
    "        '''\n",
    "        super(Subclass,self).__init__()\n",
    "        assert isinstance(dataset, CacheClassLabel), 'dataset must be wrapped by CacheClassLabel'\n",
    "        self.dataset = dataset\n",
    "        self.class_list = class_list\n",
    "        self.remap = remap\n",
    "        self.indices = []\n",
    "        for c in class_list:\n",
    "            self.indices.extend((dataset.labels==c).nonzero().flatten().tolist())\n",
    "        if remap:\n",
    "            self.class_mapping = {c: i for i, c in enumerate(class_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, index):\n",
    "        img,target = self.dataset[self.indices[index]]\n",
    "        if self.remap:\n",
    "            raw_target = target.item() if isinstance(target,torch.Tensor) else target\n",
    "            target = self.class_mapping[raw_target]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitGen(train_dataset, val_dataset, first_split_sz=2, other_split_sz=2, rand_split=False, remap_class=False):\n",
    "    assert train_dataset.number_classes==val_dataset.number_classes,'Train/Val has different number of classes'\n",
    "    num_classes =  train_dataset.number_classes\n",
    "\n",
    "    # Calculate the boundary index of classes for splits\n",
    "    # Ex: [0,2,4,6,8,10] or [0,50,60,70,80,90,100]\n",
    "    split_boundaries = [0, first_split_sz]\n",
    "    while split_boundaries[-1]<num_classes:\n",
    "        split_boundaries.append(split_boundaries[-1]+other_split_sz)\n",
    "    print('split_boundaries:',split_boundaries)\n",
    "    assert split_boundaries[-1]==num_classes,'Invalid split size'\n",
    "\n",
    "    # Assign classes to each splits\n",
    "    # Create the dict: {split_name1:[2,6,7], split_name2:[0,3,9], ...}\n",
    "    if not rand_split:\n",
    "        class_lists = {str(i):list(range(split_boundaries[i-1],split_boundaries[i])) for i in range(1,len(split_boundaries))}\n",
    "    else:\n",
    "        randseq = torch.randperm(num_classes)\n",
    "        class_lists = {str(i):randseq[list(range(split_boundaries[i-1],split_boundaries[i]))].tolist() for i in range(1,len(split_boundaries))}\n",
    "    print(class_lists)\n",
    "\n",
    "    # Generate the dicts of splits\n",
    "    # Ex: {split_name1:dataset_split1, split_name2:dataset_split2, ...}\n",
    "    train_dataset_splits = {}\n",
    "    val_dataset_splits = {}\n",
    "    task_output_space = {}\n",
    "    for name,class_list in class_lists.items():\n",
    "        train_dataset_splits[name] = AppendName(Subclass(train_dataset, class_list, remap_class), name)\n",
    "        val_dataset_splits[name] = AppendName(Subclass(val_dataset, class_list, remap_class), name)\n",
    "        task_output_space[name] = len(class_list)\n",
    "\n",
    "    return train_dataset_splits, val_dataset_splits, task_output_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST(dataroot, train_aug=False):\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Pad(2, fill=0, padding_mode='constant'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    train_transform = val_transform\n",
    "    if train_aug:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=dataroot,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_dataset = CacheClassLabel(train_dataset)\n",
    "\n",
    "    val_dataset = torchvision.datasets.MNIST(\n",
    "        dataroot,\n",
    "        train=False,\n",
    "        transform=val_transform\n",
    "    )\n",
    "    val_dataset = CacheClassLabel(val_dataset)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n",
      "./data\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = MNIST('./data', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_boundaries: [0, 2, 4, 6, 8, 10]\n",
      "{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset_splits, val_dataset_splits, task_output_space = SplitGen(train_dataset, val_dataset,\n",
    "                                                                          first_split_sz=2,\n",
    "                                                                          other_split_sz=2,\n",
    "                                                                          rand_split=False,\n",
    "                                                                          remap_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, out_dim=10, in_channel=1, img_sz=32, hidden_dim=256):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_dim = in_channel*img_sz*img_sz\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.last = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.linear(x.view(-1,self.in_dim))\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP400():\n",
    "    return MLP(hidden_dim=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = float(self.sum) / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        batch_size = target.size(0)\n",
    "        correct = (predicted == target).sum().item() * 100\n",
    "    return correct / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_acc(output, target, meter):\n",
    "    acc = accuracy(output, target)\n",
    "    meter.update(acc, len(target))\n",
    "    return meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_fn(criterion, preds, targets, valid_out_dim):\n",
    "    if valid_out_dim != 0:\n",
    "        pred = preds[:,:valid_out_dim]\n",
    "    loss = criterion(pred, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_task(follower, train_loader, optimizer_F, optimizer_L, criterion, \n",
    "                  valid_out_dim, best_model_wts, task_num, task_names):\n",
    "    leader = MLP400().to(device)\n",
    "    optimizer_L = torch.optim.Adam(leader.parameters(), 0.0005)\n",
    "    best_loss = float('inf')\n",
    "    with torch.no_grad(): \n",
    "        if (best_model_wts):\n",
    "            leader.load_state_dict(best_model_wts)\n",
    "        else:\n",
    "            leader.load_state_dict(follower.state_dict())\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        print(f'Epoch: [ {epoch} / {epoches} ]')\n",
    "        train_acc = AverageMeter()\n",
    "        batch_num = 0\n",
    "        for images, labels, _ in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            follower.train()\n",
    "            with torch.no_grad():\n",
    "                leader_outputs = leader(images)\n",
    "\n",
    "            follower_outputs = follower(images)\n",
    "            \n",
    "            c_loss_F = criterion_fn(criterion, follower_outputs, labels, valid_out_dim)\n",
    "            reg_F = torch.mean(torch.abs(follower_outputs - leader_outputs))\n",
    "            loss_F = c_loss_F + reg_F\n",
    "\n",
    "            optimizer_F.zero_grad()\n",
    "            loss_F.backward()\n",
    "            optimizer_F.step()\n",
    "\n",
    "            leader.train()\n",
    "            optimizer_L.zero_grad()\n",
    "            leader_outputs = leader(images)\n",
    "\n",
    "            c_loss_L = criterion_fn(criterion, leader_outputs, labels, valid_out_dim)\n",
    "            reg_L = torch.mean(torch.abs(follower_outputs.detach() - leader_outputs))\n",
    "            loss_L = c_loss_L + reg_L\n",
    "\n",
    "            optimizer_L.zero_grad()\n",
    "            loss_L.backward()\n",
    "            optimizer_L.step()\n",
    "\n",
    "            train_acc = accumulate_acc(follower_outputs, labels, train_acc)\n",
    "\n",
    "\n",
    "            batch_num += 1\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        follower.load_state_dict(best_model_wts) \n",
    "    '''\n",
    "        \n",
    "    return leader.state_dict(), best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(acc_table, model, train_name, task_names, task_index):\n",
    "    acc_table[train_name] = OrderedDict()\n",
    "\n",
    "    for j in range(task_index+1):\n",
    "        val_name = task_names[j]\n",
    "        val_data = val_dataset_splits[val_name]\n",
    "        val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "        model.eval()\n",
    "        val_acc = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target, _) in enumerate(val_loader):\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    output = model(input)\n",
    "                    val_acc = accumulate_acc(output, target, val_acc)\n",
    "\n",
    "        acc_table[val_name][train_name] = val_acc.avg\n",
    "    \n",
    "    return acc_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(task_names):\n",
    "    leader_acc_table = OrderedDict()\n",
    "    follower_acc_table = OrderedDict()\n",
    "    valid_out_dim = 0\n",
    "\n",
    "    model = MLP400().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_F = torch.optim.Adam(model.parameters(), 0.0005)\n",
    "\n",
    "    best_model_wts = None\n",
    "    best_loss = float('inf')\n",
    "    for i in range(len(task_names)):\n",
    "        valid_out_dim += 2\n",
    "        train_name = task_names[i]\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset_splits[train_name], batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f'=====Task: {train_name}=====')\n",
    "        best_model_wts, best_loss = train_on_task(model, train_loader, optimizer_F, None, criterion, valid_out_dim, best_model_wts, i, task_names)\n",
    "    \n",
    "        follower_acc_table[train_name] = OrderedDict()\n",
    "\n",
    "        leader = MLP400().to(device)\n",
    "        leader.load_state_dict(best_model_wts)\n",
    "        eval(follower_acc_table, model, train_name, task_names, i)\n",
    "        eval(leader_acc_table, leader, train_name, task_names, i)\n",
    "\n",
    "        print(follower_acc_table)\n",
    "        print(leader_acc_table)\n",
    "\n",
    "    avg_acc_history = [0] * len(task_names)\n",
    "    for i in range(len(task_names)):\n",
    "        train_name = task_names[i]\n",
    "        cls_acc_sum = 0\n",
    "        for j in range(i + 1):\n",
    "            val_name = task_names[j]\n",
    "            cls_acc_sum += follower_acc_table[val_name][train_name]\n",
    "\n",
    "        avg_acc_history[i] = cls_acc_sum / (i + 1)\n",
    "        print('follower Task', train_name, 'average acc:', avg_acc_history[i])\n",
    "    \n",
    "    leader_avg_acc_history = [0] * len(task_names)\n",
    "    for i in range(len(task_names)):\n",
    "        train_name = task_names[i]\n",
    "        cls_acc_sum = 0\n",
    "        for j in range(i + 1):\n",
    "            val_name = task_names[j]\n",
    "            cls_acc_sum += leader_acc_table[val_name][train_name]\n",
    "\n",
    "        leader_avg_acc_history[i] = cls_acc_sum / (i + 1)\n",
    "        print('leader Task', train_name, 'average acc:', leader_avg_acc_history[i])\n",
    "    \n",
    "    return avg_acc_history, leader_avg_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task order: ['1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "task_names = sorted(list(task_output_space.keys()), key=int)\n",
    "print('Task order:',task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Task: 1=====\n",
      "Epoch: [ 0 / 1 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587)]))])\n",
      "=====Task: 2=====\n",
      "Epoch: [ 0 / 1 ]\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0)])), ('2', OrderedDict([('2', 98.92262487757101)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0)])), ('2', OrderedDict([('2', 99.06953966699314)]))])\n",
      "=====Task: 3=====\n",
      "Epoch: [ 0 / 1 ]\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0)])), ('2', OrderedDict([('2', 98.92262487757101), ('3', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0)])), ('2', OrderedDict([('2', 99.06953966699314), ('3', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878)]))])\n",
      "=====Task: 4=====\n",
      "Epoch: [ 0 / 1 ]\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0), ('4', 0.0)])), ('2', OrderedDict([('2', 98.92262487757101), ('3', 0.0), ('4', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878), ('4', 0.0)])), ('4', OrderedDict([('4', 99.74823766364553)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0), ('4', 0.0)])), ('2', OrderedDict([('2', 99.06953966699314), ('3', 0.0), ('4', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878), ('4', 0.0)])), ('4', OrderedDict([('4', 99.74823766364553)]))])\n",
      "=====Task: 5=====\n",
      "Epoch: [ 0 / 1 ]\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0), ('4', 0.0), ('5', 0.0)])), ('2', OrderedDict([('2', 98.92262487757101), ('3', 0.0), ('4', 0.0), ('5', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878), ('4', 0.0), ('5', 0.0)])), ('4', OrderedDict([('4', 99.74823766364553), ('5', 0.0)])), ('5', OrderedDict([('5', 98.53756933938477)]))])\n",
      "OrderedDict([('1', OrderedDict([('1', 99.90543735224587), ('2', 0.0), ('3', 0.0), ('4', 0.0), ('5', 0.0)])), ('2', OrderedDict([('2', 99.06953966699314), ('3', 0.0), ('4', 0.0), ('5', 0.0)])), ('3', OrderedDict([('3', 99.73319103521878), ('4', 0.0), ('5', 0.0)])), ('4', OrderedDict([('4', 99.74823766364553), ('5', 0.0)])), ('5', OrderedDict([('5', 98.68885526979324)]))])\n",
      "follower Task 1 average acc: 99.90543735224587\n",
      "follower Task 2 average acc: 49.461312438785505\n",
      "follower Task 3 average acc: 33.24439701173959\n",
      "follower Task 4 average acc: 24.93705941591138\n",
      "follower Task 5 average acc: 19.707513867876955\n",
      "leader Task 1 average acc: 99.90543735224587\n",
      "leader Task 2 average acc: 49.53476983349657\n",
      "leader Task 3 average acc: 33.24439701173959\n",
      "leader Task 4 average acc: 24.93705941591138\n",
      "leader Task 5 average acc: 19.737771053958646\n"
     ]
    }
   ],
   "source": [
    "avg_acc_history,leader_avg_acc_history = train(task_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
